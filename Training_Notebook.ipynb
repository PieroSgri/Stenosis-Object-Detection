{"cells":[{"cell_type":"markdown","metadata":{"id":"Iirsmw151gwy"},"source":["## Tools setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wrfYjFuUQt2e"},"outputs":[],"source":["import os\n","import shutil\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","!rm -r sample_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTBYWlnKSD78"},"outputs":[],"source":["# to hide cell output\n","%%capture\n","\n","!pip install tensorflow==2.*\n","#!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n","\n","!git clone https://github.com/tensorflow/models.git\n","\n","# Compile protos.\n","%cd models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","%cd /content\n","!pip install cython\n","\n","!git clone https://github.com/cocodataset/cocoapi.git\n","%cd cocoapi/PythonAPI\n","!make\n","\n","%cp -r pycocotools /content/models/research\n","\n","%cd /content/models/research\n","%cp object_detection/packages/tf2/setup.py .\n","!python -m pip install .\n","\n","# Test\n","#!python object_detection/builders/model_builder_tf2_test.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C5Q3VC72cOHK"},"outputs":[],"source":["workspace_path = '/content/drive/MyDrive/CVproject_Stenosis/workspace'\n","models_path = '/content/drive/MyDrive/CVproject_Stenosis/workspace/models'\n","pre_trained_models_path = '/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models'\n","exported_models_path = '/content/drive/MyDrive/CVproject_Stenosis/workspace/exported_models'\n","tfrecord_output_path = '/content/drive/MyDrive/CVproject_Stenosis/workspace/data'\n","train_record_path = '/content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record'\n","validation_record_path = '/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record'\n","test_record_path = '/content/drive/MyDrive/CVproject_Stenosis/workspace/data/test.record'\n","label_map_path = '/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt'\n","dataset_path = '/content/drive/MyDrive/CVproject_Stenosis/Dataset'\n","images_path = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/Images'\n","csv_path = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","\n","object_detection_path = '/content/models/research/object_detection'\n","model_main_tf2 = 'model_main_tf2.py'\n","exporter_main_v2 = 'exporter_main_v2.py'\n","\n","#copy_path1 = os.path.join(object_detection_path, model_main_tf2)\n","#copy_path2 = os.path.join(workspace_path, model_main_tf2)\n","#shutil.copy(copy_path1, copy_path2)\n","\n","#copy_path1 = os.path.join(object_detection_path, exporter_main_v2)\n","#copy_path2 = os.path.join(workspace_path, exporter_main_v2)\n","#shutil.copy(copy_path1, copy_path2)\n","\n","num_train_samples = 6700 # Sono 6692 in realtÃ  ma mi sta comodo 6700 per fa i calcoli\n","num_eval_samples = 800\n","num_test_samples = 833"]},{"cell_type":"markdown","source":["### Helper functions"],"metadata":{"id":"YNcCCch9z3qz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SV5GSS4NsAVK"},"outputs":[],"source":["# Helper functions\n","\n","def detect_fn(image):\n","    \"\"\"\n","    Detect objects in image.\n","    \n","    Args:\n","      image: (tf.tensor): 4D input image\n","      \n","    Returs:\n","      detections (dict): predictions that model made\n","    \"\"\"\n","\n","    image, shapes = detection_model.preprocess(image)\n","    prediction_dict = detection_model.predict(image, shapes)\n","    detections = detection_model.postprocess(prediction_dict, shapes)\n","\n","    return detections\n","\n","\n","def load_image_into_numpy_array(path):\n","    \"\"\"Load an image from file into a numpy array.\n","\n","    Puts image into numpy array to feed into tensorflow graph.\n","    Note that by convention we put it into a numpy array with shape\n","    (height, width, channels), where channels=3 for RGB.\n","\n","    Args:\n","      path: the file path to the image\n","\n","    Returns:\n","      numpy array with shape (img_height, img_width, 3)\n","    \"\"\"\n","    \n","    return np.array(Image.open(path))\n","\n","\n","def nms(rects, thd=0.5):\n","    \"\"\"\n","    Filter rectangles\n","    rects is array of oblects ([x1,y1,x2,y2], confidence, class)\n","    thd - intersection threshold (intersection divides min square of rectange)\n","    \"\"\"\n","    out = []\n","\n","    remove = [False] * len(rects)\n","\n","    for i in range(0, len(rects) - 1):\n","        if remove[i]:\n","            continue\n","        inter = [0.0] * len(rects)\n","        for j in range(i, len(rects)):\n","            if remove[j]:\n","                continue\n","            inter[j] = intersection(rects[i][0], rects[j][0]) / min(square(rects[i][0]), square(rects[j][0]))\n","\n","        max_prob = 0.0\n","        max_idx = 0\n","        for k in range(i, len(rects)):\n","            if inter[k] >= thd:\n","                if rects[k][1] > max_prob:\n","                    max_prob = rects[k][1]\n","                    max_idx = k\n","\n","        for k in range(i, len(rects)):\n","            if (inter[k] >= thd) & (k != max_idx):\n","                remove[k] = True\n","\n","    for k in range(0, len(rects)):\n","        if not remove[k]:\n","            out.append(rects[k])\n","\n","    boxes = [box[0] for box in out]\n","    scores = [score[1] for score in out]\n","    classes = [cls[2] for cls in out]\n","    return boxes, scores, classes\n","\n","\n","def intersection(rect1, rect2):\n","    \"\"\"\n","    Calculates square of intersection of two rectangles\n","    rect: list with coords of top-right and left-boom corners [x1,y1,x2,y2]\n","    return: square of intersection\n","    \"\"\"\n","    x_overlap = max(0, min(rect1[2], rect2[2]) - max(rect1[0], rect2[0]));\n","    y_overlap = max(0, min(rect1[3], rect2[3]) - max(rect1[1], rect2[1]));\n","    overlapArea = x_overlap * y_overlap;\n","    return overlapArea\n","\n","\n","def square(rect):\n","    \"\"\"\n","    Calculates square of rectangle\n","    \"\"\"\n","    return abs(rect[2] - rect[0]) * abs(rect[3] - rect[1])\n","\n","\n","def inference_with_plot(path2images, draw_groundtruth=True, annotations_df=None, box_th=0.25):\n","    \"\"\"\n","    Function that performs inference and plots resulting b-boxes\n","    \n","    Args:\n","      path2images: an array with pathes to images\n","      draw_groundtruth: if True will draw ground truth bbox, a pandas dataframe with annotations is needed\n","      annotations_dataframe: a pandas dataframe containing bbox annotations for ground truth\n","      box_th: (float) value that defines threshold for model prediction.\n","      \n","    Returns:\n","      None\n","    \"\"\"\n","    for image_path in path2images:\n","\n","        image_name = os.path.basename(image_path)\n","        print('Running inference for {}... '.format(image_name), end='')\n","        start_time = time.time()\n","\n","        image_np = load_image_into_numpy_array(image_path)\n","        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","        detections = detect_fn(input_tensor)\n","\n","        # All outputs are batches tensors.\n","        # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","        # We're only interested in the first num_detections.\n","        num_detections = int(detections.pop('num_detections'))\n","        detections = {key: value[0, :num_detections].numpy()\n","                      for key, value in detections.items()}\n","        \n","        detections['num_detections'] = num_detections\n","\n","        # detection_classes should be ints.\n","        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","        label_id_offset = 1\n","        image_np_with_detections = image_np.copy()\n","\n","        viz_utils.visualize_boxes_and_labels_on_image_array(\n","                image_np_with_detections,\n","                detections['detection_boxes'],\n","                detections['detection_classes']+label_id_offset,\n","                detections['detection_scores'],\n","                category_index,\n","                use_normalized_coordinates=True,\n","                max_boxes_to_draw=200,\n","                min_score_thresh=box_th,\n","                agnostic_mode=False,\n","                line_thickness=3)\n","\n","        #Code for drawing ground truth box\n","        if draw_groundtruth is True:\n","            xmin = annotations_df.loc[annotations_df['filename'] == image_name, 'xmin'].values[0]\n","            ymin = annotations_df.loc[annotations_df['filename'] == image_name, 'ymin'].values[0]\n","            xmax = annotations_df.loc[annotations_df['filename'] == image_name, 'xmax'].values[0]\n","            ymax = annotations_df.loc[annotations_df['filename'] == image_name, 'ymax'].values[0]\n","\n","            viz_utils.draw_bounding_box_on_image_array(\n","                    image_np_with_detections,\n","                    ymin,\n","                    xmin,\n","                    ymax,\n","                    xmax,\n","                    use_normalized_coordinates=False,\n","                    display_str_list=['Real Stenosis'],\n","                    color='red',\n","                    thickness=2)\n","        \n","        plt.figure(figsize=(15,10))\n","        plt.imshow(image_np_with_detections)\n","        end_time = time.time() - start_time\n","        end_time = round(end_time, 2)\n","        print('Done.', 'took: ', end_time, ' s')\n","    plt.show()\n","\n","\n","def edit_configfile(conf_path, label_map_path, checkpoint_path, train_record_path, validation_record_path, batch_size, num_steps, is_ssdmodel=False):\n","\n","    with open(conf_path, 'r') as f:\n","        config = f.read()\n","\n","    with open(conf_path, 'w') as f:\n","\n","        # Set labelmap path\n","        config = re.sub('label_map_path: \".*?\"', \n","                        'label_map_path: \"{}\"'.format(label_map_path), config)\n","    \n","        # Set fine_tune_checkpoint path\n","        config = re.sub('fine_tune_checkpoint: \".*?\"',\n","                        'fine_tune_checkpoint: \"{}\"'.format(checkpoint_path), config)\n","\n","        if is_ssdmodel is False:\n","        # Set train tf-record file path\n","            config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n","                            'input_path: \"{}\"'.format(train_record_path), config)\n","\n","        else:\n","            config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED)(.*?\")', \n","                            'input_path: \"{}\"'.format(train_record_path), config, count=1)\n","\n","        if is_ssdmodel is False:\n","            # Set validation tf-record file path FOR SSD MODEL\n","            config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n","                            'input_path: \"{}\"'.format(validation_record_path), config)\n","\n","        else:\n","            # Set validation tf-record file path FOR SSD MODEL\n","            config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED)(.*?\")', \n","                            'input_path: \"{}\"'.format(validation_record_path), config, count=1)\n","    \n","\n","        # Set number of classes.\n","        config = re.sub('num_classes: [0-9]+',\n","                    'num_classes: {}'.format(1), config)\n","    \n","        # Set batch size\n","        config = re.sub('batch_size: [0-9]+',\n","                        'batch_size: {}'.format(batch_size), config)\n","    \n","        # Set training steps\n","        config = re.sub('num_steps: [0-9]+',\n","                        'num_steps: {}'.format(num_steps), config)\n","        \n","        # Set optimizer steps\n","        config = re.sub('total_steps: [0-9]+',\n","                        'total_steps: {}'.format(num_steps), config)\n","    \n","        # Set fine-tune checkpoint type to detection\n","        config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n","                        'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n","    \n","        f.write(config)\n","\n","\n","def normalize_bbox(bbox, rows, cols):\n","    \"\"\"Normalize coordinates of a bounding box. Divide x-coordinates by image width and y-coordinates\n","    by image height.\n","\n","    Args:\n","        bbox (tuple): Denormalized bounding box `(x_min, y_min, x_max, y_max)`.\n","        rows (int): Image height.\n","        cols (int): Image width.\n","\n","    Returns:\n","        tuple: Normalized bounding box `(x_min, y_min, x_max, y_max)`.\n","\n","    Raises:\n","        ValueError: If rows or cols is less or equal zero\n","\n","    \"\"\"\n","    (x_min, y_min, x_max, y_max), tail = bbox[:4], tuple(bbox[4:])\n","\n","    if rows <= 0:\n","        raise ValueError(\"Argument rows must be positive integer\")\n","    if cols <= 0:\n","        raise ValueError(\"Argument cols must be positive integer\")\n","\n","    x_min, x_max = x_min / cols, x_max / cols\n","    y_min, y_max = y_min / rows, y_max / rows\n","\n","    return (x_min, y_min, x_max, y_max) + tail"]},{"cell_type":"markdown","source":["## Utils"],"metadata":{"id":"WyLVuqvm2G4A"}},{"cell_type":"markdown","metadata":{"id":"55FWnxOB2T_M"},"source":["### Generazione dei TFrecord per train, test e validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWoavPTa2T_M"},"outputs":[],"source":["# CSV path:      /content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV\n","# Images path:   /content/drive/MyDrive/CVproject_Stenosis/Dataset/Images\n","# TFrecord path: /content/drive/MyDrive/CVproject_Stenosis/workspace/data\n","# Gen TFrecord:  /content/drive/MyDrive/CVproject_Stenosis/workspace/generate_tfrecord.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wgm3QHdh2T_M"},"outputs":[],"source":["'''\n","train_images_path = os.path.join(images_path, 'train')\n","train_csv_path = os.path.join(csv_path, 'train.csv')\n","\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/generate_tfrecord.py \\\n","    --csv_input=$train_csv_path \\\n","    --image_dir=$train_images_path \\\n","    --output_path=$train_record_path\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_jXtmnxN2T_M"},"outputs":[],"source":["'''\n","test_images_path = os.path.join(images_path, 'test')\n","test_csv_path = os.path.join(csv_path, 'test.csv')\n","\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/generate_tfrecord.py \\\n","    --csv_input=$test_csv_path \\\n","    --image_dir=$test_images_path \\\n","    --output_path=$test_record_path\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfUKWtQs2T_M"},"outputs":[],"source":["'''\n","validation_images_path = os.path.join(images_path, 'validation')\n","validation_csv_path = os.path.join(csv_path, 'validation.csv')\n","\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/generate_tfrecord.py \\\n","    --csv_input=$validation_csv_path \\\n","    --image_dir=$validation_images_path \\\n","    --output_path=$validation_record_path\n","'''"]},{"cell_type":"markdown","source":["### Check vari sulle immagini e sui tfrecord"],"metadata":{"id":"ElEs4KKA2MxE"}},{"cell_type":"code","source":["from PIL import Image\n","import numpy as np\n","\n","img = Image.open(\"/content/drive/MyDrive/CVproject_Stenosis/Dataset/Images/train/14_018_6_0017.bmp\")\n","img_np = np.asarray(img)\n","print(\"img_np.shape: \", img_np.shape)\n","\n","#<xmin>100</xmin><ymin>141</ymin><xmax>149</xmax><ymax>176</ymax>\n","tup = (100, 141, 149, 176)\n","normalize_bbox(tup, 512, 512)\n"],"metadata":{"id":"QY_NYEiq2MxE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf \n","raw_dataset1 = tf.data.TFRecordDataset(\"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record\")\n","raw_dataset2 = tf.data.TFRecordDataset(\"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/test.record\")\n","raw_dataset3 = tf.data.TFRecordDataset(\"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")\n","print(raw_dataset1)\n","print(raw_dataset2)\n","print(raw_dataset3)"],"metadata":{"id":"pOLm3ySrKzPv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SSD ResNet50 V1 FPN 640x640"],"metadata":{"id":"MCMXTAe5KUso"}},{"cell_type":"markdown","metadata":{"id":"dumMdgt0KfsH"},"source":["## V1"]},{"cell_type":"markdown","metadata":{"id":"rO4S-ua2KfsI"},"source":["### Configuration"]},{"cell_type":"code","source":["# ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\n","\n","# ----------------------------------- BEGIN MODEL SETTINGS --------------------------------------- #\n","%cd $pre_trained_models_path\n","# SET DOWNLOAD LINK AND MODEL TECH NAME + .tar.gz\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","# SET MODEL TECH NAME + .tar.gz\n","!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","%rm ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","\n","%cd .."],"metadata":{"id":"hlc77hqrKfsI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wiwies32KfsJ"},"outputs":[],"source":["model_tech_name = 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8'\n","model_name = 'ssd_resnet50'\n","version_name = 'v1'\n","\n","model_path = os.path.join(models_path, model_name)\n","version_path = os.path.join(model_path, version_name)\n","\n","train_log_path = os.path.join(version_path, 'train')\n","eval_log_path = os.path.join(version_path, 'eval')\n","log_path = version_path\n","\n","pre_trained_conf_path = os.path.join(pre_trained_models_path, model_tech_name, 'pipeline.config')\n","model_conf_path = os.path.join(models_path, model_name, version_name, 'pipeline.config')\n","checkpoint_path = os.path.join(pre_trained_models_path, model_tech_name, 'checkpoint/ckpt-0')\n","\n","model_name_version = model_name + '_' + version_name\n","exported_model_path = os.path.join(exported_models_path, model_name_version)\n","exported_model_conf_path = os.path.join(exported_models_path, model_name_version, 'pipeline.config')\n","\n","batch_size = 2\n","num_epoch = 7.5\n","num_steps = int(num_train_samples / batch_size) * num_epoch\n","num_steps += 100\n","print(num_steps)\n","# ------------------------------------- END MODEL SETTINGS --------------------------------------- #"]},{"cell_type":"code","source":["if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","if not os.path.exists(version_path):\n","    os.mkdir(version_path)\n","if not os.path.exists(version_path + \"/eval\"):\n","    os.mkdir(version_path + \"/eval\")\n","if not os.path.exists(version_path + \"/train\"):\n","    os.mkdir(version_path + \"/train\")\n","if not os.path.exists(version_path + \"/custom_ckpt\"):\n","    os.mkdir(version_path + \"/custom_ckpt\")\n","\n","shutil.copy(pre_trained_conf_path, model_conf_path)"],"metadata":{"id":"YBwX0MmMKfsJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modifiche manuali al config file:\n","# momentum_optimizer sembra essere il migliore in termini di loss\n","'''\n","model {\n","  ssd {\n","    num_classes: 1\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 640\n","        width: 640\n","      }\n","    }\n","    feature_extractor {\n","      type: \"ssd_resnet50_v1_fpn_keras\"\n","      depth_multiplier: 1.0\n","      min_depth: 16\n","      conv_hyperparams {\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00039999998989515007\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            mean: 0.0\n","            stddev: 0.029999999329447746\n","          }\n","        }\n","        activation: RELU_6\n","        batch_norm {\n","          decay: 0.996999979019165\n","          scale: true\n","          epsilon: 0.0010000000474974513\n","        }\n","      }\n","      override_base_feature_extractor_hyperparams: true\n","      fpn {\n","        min_level: 3\n","        max_level: 7\n","      }\n","    }\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        conv_hyperparams {\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00039999998989515007\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              mean: 0.0\n","              stddev: 0.009999999776482582\n","            }\n","          }\n","          activation: RELU_6\n","          batch_norm {\n","            decay: 0.996999979019165\n","            scale: true\n","            epsilon: 0.0010000000474974513\n","          }\n","        }\n","        depth: 256\n","        num_layers_before_predictor: 4\n","        kernel_size: 3\n","        class_prediction_bias_init: -4.599999904632568\n","      }\n","    }\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 3.0\n","        aspect_ratios: [0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.25, 2.50, 2.75, 3.0]\n","        scales_per_octave: 2\n","      }\n","    }\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.2\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","        use_static_shapes: false\n","      }\n","      score_converter: SIGMOID\n","    }\n","    normalize_loss_by_num_matches: true\n","    loss {\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          gamma: 2.0\n","          alpha: 0.25\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    encode_background_as_zeros: true\n","    normalize_loc_loss_by_codesize: true\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","  }\n","}\n","train_config {\n","  batch_size: 2\n","  num_steps: 25200\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0003\n","          schedule {\n","            step: 13000\n","            learning_rate: 0.00003\n","          }\n","          schedule {\n","            step: 20000\n","            learning_rate: 0.000003\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","        probability: 0.5\n","    }\n","    random_pixel_value_scale {\n","        probability: 0.5\n","        minval: 0.9\n","        maxval: 1.1\n","    }\n","    random_adjust_brightness {\n","        probability: 0.5\n","        max_delta: 0.2\n","    }\n","    random_adjust_contrast {\n","        probability: 0.5\n","        min_delta: 0.8\n","        max_delta: 1.2\n","    }\n","  }\n","\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  fine_tune_checkpoint_type: \"detection\"\n","  use_bfloat16: false\n","  fine_tune_checkpoint_version: V2\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 1;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\"\n","  }\n","}\n","'''"],"metadata":{"id":"8bN1Z7mZKfsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","test_conf_path = version_path + \"/test.config\"\n","with open(model_conf_path, 'r') as f:\n","    config = f.read()\n","with open(test_conf_path, 'w') as f:\n","    config = re.sub('(input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")', 'input_path: \"{}\"'.format(test_record_path), config)\n","    f.write(config)"],"metadata":{"id":"bBcQBqjkKfsL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"imTUNcYnKfsL"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDcbt_PfKfsL"},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_qIM1e6KfsL"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path/train"]},{"cell_type":"code","source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path"],"metadata":{"id":"73iVdxC6vDNI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qqO5taSVKfsM"},"outputs":[],"source":["# TRAINING\n","#checkpoint_every_n = int(num_train_samples / batch_size)\n","checkpoint_every_n = 1000\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/model_main_tf2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --model_dir=$version_path \\\n","  --checkpoint_every_n=$checkpoint_every_n \\"]},{"cell_type":"code","source":["ckpt_path = version_path + \"/checkpoint\"\n","cust_ckpt_path = version_path + \"/custom_ckpt\"\n","ckpt_data = version_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx = version_path + \"/ckpt-26.index\"\n","ckpt_data2 = cust_ckpt_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx2 = cust_ckpt_path + \"/ckpt-26.index\"\n","!cp $ckpt_path $cust_ckpt_path/checkpoint\n","!cp $ckpt_data $ckpt_data2\n","!cp $ckpt_idx $ckpt_idx2\n","import re\n","with open(cust_ckpt_path + \"/checkpoint\", 'r') as f:\n","    content = f.read()\n","with open(cust_ckpt_path + \"/checkpoint\", 'w') as f:\n","    content = re.sub('(model_checkpoint_path: \"{}\")'.format(\"ckpt-26\"), 'model_checkpoint_path: \"{}\"'.format(\"ckpt-26\"), content)\n","    f.write(content)"],"metadata":{"id":"f1hDOGXuKfsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQCnYjQBKfsM"},"outputs":[],"source":["# EXPORTER\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/exporter_main_v2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --trained_checkpoint_dir=$version_path/custom_ckpt \\\n","  --output_directory=$exported_model_path \\\n","  --input_type=image_tensor"]},{"cell_type":"markdown","metadata":{"id":"YdZG1D9QKfsM"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hI7smSVSKfsN"},"outputs":[],"source":["import tensorflow as tf # import tensorflow\n","\n","# checking that GPU is found\n","if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")\n","\n","# other import\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","import time\n","\n","%cd /content\n","\n","import sys # importyng sys in order to access scripts located in a different folder\n","\n","path2scripts = '/content/models/research' \n","sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n","\n","path2annotations = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","train_annotations = pd.read_csv(os.path.join(path2annotations, 'train.csv'))\n","test_annotations = pd.read_csv(os.path.join(path2annotations, 'test.csv'))\n","validation_annotations = pd.read_csv(os.path.join(path2annotations, 'validation.csv'))\n","\n","# importing all scripts that will be needed to export your model and use it for inference\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n","\n","# specify which device you want to work on.\n","# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # specify your computational device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzUf91qSKfsN"},"outputs":[],"source":["path2config = exported_model_conf_path\n","path2model = exported_model_path + '/'\n","\n","configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n","model_config = configs['model'] # recreating model config\n","detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(path2model, 'checkpoint/ckpt-0')).expect_partial()\n","\n","path2label_map = label_map_path\n","category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rwDnlXpEKfsN"},"outputs":[],"source":["%matplotlib inline\n","train_samples = []\n","test_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'test')):\n","    test_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","train_samples = train_samples[start:end] # per testarne di meno di tutta la cartella\n","test_samples = test_samples[20:40]\n","\n","inference_with_plot(test_samples, draw_groundtruth=True, annotations_df=test_annotations, box_th=0.30)"]},{"cell_type":"markdown","metadata":{"id":"K5Us5TrcE9Xa"},"source":["## V2"]},{"cell_type":"markdown","metadata":{"id":"fg2i-PRQE9Xa"},"source":["### Configuration"]},{"cell_type":"code","source":["# ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\n","\n","# ----------------------------------- BEGIN MODEL SETTINGS --------------------------------------- #\n","%cd $pre_trained_models_path\n","# SET DOWNLOAD LINK AND MODEL TECH NAME + .tar.gz\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","# SET MODEL TECH NAME + .tar.gz\n","!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","%rm ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","\n","%cd .."],"metadata":{"id":"WGJ_bKKkE9Xa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y_R-DIUVE9Xb"},"outputs":[],"source":["model_tech_name = 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8'\n","model_name = 'ssd_resnet50'\n","version_name = 'v2'\n","\n","model_path = os.path.join(models_path, model_name)\n","version_path = os.path.join(model_path, version_name)\n","\n","train_log_path = os.path.join(version_path, 'train')\n","eval_log_path = os.path.join(version_path, 'eval')\n","log_path = version_path\n","\n","pre_trained_conf_path = os.path.join(pre_trained_models_path, model_tech_name, 'pipeline.config')\n","model_conf_path = os.path.join(models_path, model_name, version_name, 'pipeline.config')\n","checkpoint_path = os.path.join(pre_trained_models_path, model_tech_name, 'checkpoint/ckpt-0')\n","\n","model_name_version = model_name + '_' + version_name\n","exported_model_path = os.path.join(exported_models_path, model_name_version)\n","exported_model_conf_path = os.path.join(exported_models_path, model_name_version, 'pipeline.config')\n","\n","batch_size = 2\n","num_epoch = 7.5\n","num_steps = int(num_train_samples / batch_size) * num_epoch\n","num_steps += 100\n","print(num_steps)\n","# ------------------------------------- END MODEL SETTINGS --------------------------------------- #"]},{"cell_type":"code","source":["if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","if not os.path.exists(version_path):\n","    os.mkdir(version_path)\n","if not os.path.exists(version_path + \"/eval\"):\n","    os.mkdir(version_path + \"/eval\")\n","if not os.path.exists(version_path + \"/train\"):\n","    os.mkdir(version_path + \"/train\")\n","if not os.path.exists(version_path + \"/custom_ckpt\"):\n","    os.mkdir(version_path + \"/custom_ckpt\")\n","\n","shutil.copy(pre_trained_conf_path, model_conf_path)"],"metadata":{"id":"KXYhGzttE9Xb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modifiche manuali al config file:\n","# momentum_optimizer sembra essere il migliore in termini di loss\n","'''\n","model {\n","  ssd {\n","    num_classes: 1\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 640\n","        width: 640\n","      }\n","    }\n","    feature_extractor {\n","      type: \"ssd_resnet50_v1_fpn_keras\"\n","      depth_multiplier: 1.0\n","      min_depth: 16\n","      conv_hyperparams {\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00039999998989515007\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            mean: 0.0\n","            stddev: 0.029999999329447746\n","          }\n","        }\n","        activation: RELU_6\n","        batch_norm {\n","          decay: 0.996999979019165\n","          scale: true\n","          epsilon: 0.0010000000474974513\n","        }\n","      }\n","      override_base_feature_extractor_hyperparams: true\n","      fpn {\n","        min_level: 3\n","        max_level: 7\n","      }\n","    }\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        use_dropout: true\n","        dropout_keep_probability: 0.8\n","        conv_hyperparams {\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00039999998989515007\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              mean: 0.0\n","              stddev: 0.009999999776482582\n","            }\n","          }\n","          activation: RELU_6\n","          batch_norm {\n","            decay: 0.996999979019165\n","            scale: true\n","            epsilon: 0.0010000000474974513\n","          }\n","        }\n","        depth: 256\n","        num_layers_before_predictor: 4\n","        kernel_size: 3\n","        class_prediction_bias_init: -4.599999904632568\n","      }\n","    }\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 3.0\n","        aspect_ratios: [0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.25, 2.50, 2.75, 3.0]\n","        scales_per_octave: 2\n","      }\n","    }\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.2\n","        iou_threshold: 0.1\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","        use_static_shapes: false\n","      }\n","      score_converter: SIGMOID\n","    }\n","    normalize_loss_by_num_matches: true\n","    loss {\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          gamma: 2.0\n","          alpha: 0.25\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    encode_background_as_zeros: true\n","    normalize_loc_loss_by_codesize: true\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","  }\n","}\n","train_config {\n","  batch_size: 2\n","  num_steps: 25200\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0003\n","          schedule {\n","            step: 13000\n","            learning_rate: 0.00003\n","          }\n","          schedule {\n","            step: 20000\n","            learning_rate: 0.000003\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","        probability: 0.5\n","    }\n","    random_pixel_value_scale {\n","        probability: 0.5\n","        minval: 0.9\n","        maxval: 1.3\n","    }\n","    random_adjust_brightness {\n","        probability: 0.5\n","        max_delta: 0.2\n","    }\n","    random_adjust_contrast {\n","        probability: 0.5\n","        min_delta: 0.8\n","        max_delta: 1.2\n","    }\n","  }\n","\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  fine_tune_checkpoint_type: \"detection\"\n","  use_bfloat16: false\n","  fine_tune_checkpoint_version: V2\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 1;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\"\n","  }\n","}\n","'''"],"metadata":{"id":"EaacoMmPE9Xb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","test_conf_path = version_path + \"/test.config\"\n","with open(model_conf_path, 'r') as f:\n","    config = f.read()\n","with open(test_conf_path, 'w') as f:\n","    config = re.sub('(input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")', 'input_path: \"{}\"'.format(test_record_path), config)\n","    f.write(config)"],"metadata":{"id":"QRXNEmi-E9Xb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jEC1Zu0fE9Xb"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIiXHVENE9Xc"},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1E8oJtvE9Xc"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path/train"]},{"cell_type":"code","source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path"],"metadata":{"id":"Wj4bC56sxgrn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8jpYbxD_E9Xc"},"outputs":[],"source":["# TRAINING\n","#checkpoint_every_n = int(num_train_samples / batch_size)\n","checkpoint_every_n = 1000\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/model_main_tf2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --model_dir=$version_path \\\n","  --checkpoint_every_n=$checkpoint_every_n \\"]},{"cell_type":"code","source":["ckpt_path = version_path + \"/checkpoint\"\n","cust_ckpt_path = version_path + \"/custom_ckpt\"\n","ckpt_data = version_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx = version_path + \"/ckpt-26.index\"\n","ckpt_data2 = cust_ckpt_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx2 = cust_ckpt_path + \"/ckpt-26.index\"\n","!cp $ckpt_path $cust_ckpt_path/checkpoint\n","!cp $ckpt_data $ckpt_data2\n","!cp $ckpt_idx $ckpt_idx2\n","import re\n","with open(cust_ckpt_path + \"/checkpoint\", 'r') as f:\n","    content = f.read()\n","with open(cust_ckpt_path + \"/checkpoint\", 'w') as f:\n","    content = re.sub('(model_checkpoint_path: \"{}\")'.format(\"ckpt-26\"), 'model_checkpoint_path: \"{}\"'.format(\"ckpt-26\"), content)\n","    f.write(content)"],"metadata":{"id":"Iwgj3z6XE9Xc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBT9p8aLE9Xc"},"outputs":[],"source":["# EXPORTER\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/exporter_main_v2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --trained_checkpoint_dir=$version_path/custom_ckpt \\\n","  --output_directory=$exported_model_path \\\n","  --input_type=image_tensor"]},{"cell_type":"markdown","metadata":{"id":"21Nu9KEhE9Xc"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9PS08grBE9Xc"},"outputs":[],"source":["import tensorflow as tf # import tensorflow\n","\n","# checking that GPU is found\n","if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")\n","\n","# other import\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","\n","%cd /content\n","\n","import sys # importyng sys in order to access scripts located in a different folder\n","\n","path2scripts = '/content/models/research' \n","sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n","\n","path2annotations = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","train_annotations = pd.read_csv(os.path.join(path2annotations, 'train.csv'))\n","test_annotations = pd.read_csv(os.path.join(path2annotations, 'test.csv'))\n","validation_annotations = pd.read_csv(os.path.join(path2annotations, 'validation.csv'))\n","\n","# importing all scripts that will be needed to export your model and use it for inference\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n","\n","# specify which device you want to work on.\n","# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # specify your computational device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"196nkOKeE9Xd"},"outputs":[],"source":["path2config = exported_model_conf_path\n","path2model = exported_model_path + '/'\n","\n","configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n","model_config = configs['model'] # recreating model config\n","detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(path2model, 'checkpoint/ckpt-0')).expect_partial()\n","\n","path2label_map = label_map_path\n","category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RA5KeDkJE9Xd"},"outputs":[],"source":["%matplotlib inline\n","train_samples = []\n","test_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'test')):\n","    test_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","train_samples = train_samples[start:end] # per testarne di meno di tutta la cartella\n","test_samples = test_samples[20:40]\n","\n","inference_with_plot(test_samples, draw_groundtruth=True, annotations_df=test_annotations, box_th=0.30)"]},{"cell_type":"markdown","metadata":{"id":"mBoc4lkVvEq5"},"source":["# EfficientDet D0 512x512"]},{"cell_type":"markdown","metadata":{"id":"RuRFLDRnvEq5"},"source":["## V1"]},{"cell_type":"markdown","metadata":{"id":"bIlSOX6evEq5"},"source":["### Configuration"]},{"cell_type":"code","source":["# efficientdet_d0_coco17_tpu-32\n","\n","# ----------------------------------- BEGIN MODEL SETTINGS --------------------------------------- #\n","%cd $pre_trained_models_path\n","# SET DOWNLOAD LINK AND MODEL TECH NAME + .tar.gz\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","# SET MODEL TECH NAME + .tar.gz\n","!tar -xf efficientdet_d0_coco17_tpu-32.tar.gz\n","%rm efficientdet_d0_coco17_tpu-32.tar.gz\n","\n","%cd .."],"metadata":{"id":"8CDjgD9JvEq6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5_pQQBCvEq6"},"outputs":[],"source":["model_tech_name = 'efficientdet_d0_coco17_tpu-32'\n","model_name = 'efficientdet_d0'\n","version_name = 'v1'\n","\n","model_path = os.path.join(models_path, model_name)\n","version_path = os.path.join(model_path, version_name)\n","\n","train_log_path = os.path.join(version_path, 'train')\n","eval_log_path = os.path.join(version_path, 'eval')\n","log_path = version_path\n","\n","pre_trained_conf_path = os.path.join(pre_trained_models_path, model_tech_name, 'pipeline.config')\n","model_conf_path = os.path.join(models_path, model_name, version_name, 'pipeline.config')\n","checkpoint_path = os.path.join(pre_trained_models_path, model_tech_name, 'checkpoint/ckpt-0')\n","\n","model_name_version = model_name + '_' + version_name\n","exported_model_path = os.path.join(exported_models_path, model_name_version)\n","exported_model_conf_path = os.path.join(exported_models_path, model_name_version, 'pipeline.config')\n","\n","batch_size = 4\n","num_epoch = 15\n","num_steps = int(num_train_samples / batch_size) * num_epoch\n","num_steps += 100\n","print(num_steps)\n","# ------------------------------------- END MODEL SETTINGS --------------------------------------- #"]},{"cell_type":"code","source":["if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","if not os.path.exists(version_path):\n","    os.mkdir(version_path)\n","if not os.path.exists(version_path + \"/eval\"):\n","    os.mkdir(version_path + \"/eval\")\n","if not os.path.exists(version_path + \"/train\"):\n","    os.mkdir(version_path + \"/train\")\n","if not os.path.exists(version_path + \"/custom_ckpt\"):\n","    os.mkdir(version_path + \"/custom_ckpt\")\n","\n","shutil.copy(pre_trained_conf_path, model_conf_path)"],"metadata":{"id":"JFo4gP4yvEq6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modifiche manuali al config file:\n","# momentum_optimizer sembra essere il migliore in termini di loss\n","'''\n","model {\n","  ssd {\n","    num_classes: 1\n","    image_resizer {\n","      fixed_shape_resizer {\n","          height: 512\n","          width: 512\n","      }\n","    }\n","\n","    feature_extractor {\n","      type: \"ssd_efficientnet-b0_bifpn_keras\"\n","      conv_hyperparams {\n","        regularizer {\n","          l2_regularizer {\n","            weight: 3.9999998989515007e-05\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            mean: 0.0\n","            stddev: 0.029999999329447746\n","          }\n","        }\n","        activation: SWISH\n","        batch_norm {\n","          decay: 0.9900000095367432\n","          scale: true\n","          epsilon: 0.0010000000474974513\n","        }\n","        force_use_bias: true\n","      }\n","      bifpn {\n","        min_level: 3\n","        max_level: 7\n","        num_iterations: 3\n","        num_filters: 64\n","      }\n","    }\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 1.0\n","        x_scale: 1.0\n","        height_scale: 1.0\n","        width_scale: 1.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        conv_hyperparams {\n","          regularizer {\n","            l2_regularizer {\n","              weight: 3.9999998989515007e-05\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              mean: 0.0\n","              stddev: 0.009999999776482582\n","            }\n","          }\n","          activation: SWISH\n","          batch_norm {\n","            decay: 0.9900000095367432\n","            scale: true\n","            epsilon: 0.0010000000474974513\n","          }\n","          force_use_bias: true\n","        }\n","        depth: 64\n","        num_layers_before_predictor: 3\n","        kernel_size: 3\n","        class_prediction_bias_init: -4.599999904632568\n","        use_depthwise: true\n","      }\n","    }\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: [0.5, 1.0, 1.5, 2.0]\n","        scales_per_octave: 3\n","      }\n","    }\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.2\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","    normalize_loss_by_num_matches: true\n","    loss {\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          gamma: 1.5\n","          alpha: 0.25\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 2.0\n","    }\n","    encode_background_as_zeros: true\n","    normalize_loc_loss_by_codesize: true\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    add_background_class: false\n","  }\n","}\n","\n","train_config {\n","  batch_size: 4\n","#  freeze_variables: [\"feature_extractor\"]\n","\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","    random_pixel_value_scale {\n","\n","    }\n","    random_adjust_brightness {\n","\n","    }\n","    random_adjust_contrast {\n","        \n","    }\n","  }\n","\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0003\n","          schedule {\n","            step: 15000\n","            learning_rate: 0.00003\n","          }\n","          schedule {\n","            step: 20000\n","            learning_rate: 0.00001\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n","  num_steps: 25200\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  fine_tune_checkpoint_type: \"detection\"\n","  use_bfloat16: false\n","  fine_tune_checkpoint_version: V2\n","}\n","train_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 1;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\"\n","  }\n","}\n","'''"],"metadata":{"id":"08-lwq-avEq7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","test_conf_path = version_path + \"/test.config\"\n","with open(model_conf_path, 'r') as f:\n","    config = f.read()\n","with open(test_conf_path, 'w') as f:\n","    config = re.sub('(input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")', 'input_path: \"{}\"'.format(test_record_path), config)\n","    f.write(config)"],"metadata":{"id":"ZndLsy9WYkQi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p-PscynyvEq7"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zN_9t0jDvEq7"},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCM2_4z3vEq7"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path/train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYG6Y1fhvEq8"},"outputs":[],"source":["# TRAINING\n","#checkpoint_every_n = int(num_train_samples / batch_size)\n","checkpoint_every_n = 1000\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/model_main_tf2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --model_dir=$version_path \\\n","  --checkpoint_every_n=$checkpoint_every_n \\"]},{"cell_type":"code","source":["ckpt_path = version_path + \"/checkpoint\"\n","cust_ckpt_path = version_path + \"/custom_ckpt\"\n","ckpt_data = version_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx = version_path + \"/ckpt-26.index\"\n","ckpt_data2 = cust_ckpt_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx2 = cust_ckpt_path + \"/ckpt-26.index\"\n","!cp $ckpt_path $cust_ckpt_path/checkpoint\n","!mv $ckpt_data $ckpt_data2\n","!mv $ckpt_idx $ckpt_idx2\n","import re\n","with open(cust_ckpt_path + \"/checkpoint\", 'r') as f:\n","    content = f.read()\n","with open(cust_ckpt_path + \"/checkpoint\", 'w') as f:\n","    content = re.sub('(model_checkpoint_path: \"{}\")'.format(\"ckpt-26\"), 'model_checkpoint_path: \"{}\"'.format(\"ckpt-26\"), content)\n","    f.write(content)"],"metadata":{"id":"kLDOjxJdEOax"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OrzL6G4vEq8"},"outputs":[],"source":["# EXPORTER\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/exporter_main_v2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --trained_checkpoint_dir=$version_path/custom_ckpt \\\n","  --output_directory=$exported_model_path \\\n","  --input_type=image_tensor"]},{"cell_type":"markdown","metadata":{"id":"GJ7yXdpNvEq8"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OFvnnVxnvEq8"},"outputs":[],"source":["import tensorflow as tf # import tensorflow\n","\n","# checking that GPU is found\n","if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")\n","\n","# other import\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","\n","%cd /content\n","\n","import sys # importyng sys in order to access scripts located in a different folder\n","\n","path2scripts = '/content/models/research' \n","sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n","\n","path2annotations = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","train_annotations = pd.read_csv(os.path.join(path2annotations, 'train.csv'))\n","test_annotations = pd.read_csv(os.path.join(path2annotations, 'test.csv'))\n","validation_annotations = pd.read_csv(os.path.join(path2annotations, 'validation.csv'))\n","\n","# importing all scripts that will be needed to export your model and use it for inference\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n","\n","# specify which device you want to work on.\n","# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # specify your computational device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r7pdhaZMvEq8"},"outputs":[],"source":["path2config = exported_model_conf_path\n","path2model = exported_model_path + '/'\n","\n","configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n","model_config = configs['model'] # recreating model config\n","detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(path2model, 'checkpoint/ckpt-0')).expect_partial()\n","\n","path2label_map = label_map_path\n","category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMcMCDh1vEq8"},"outputs":[],"source":["%matplotlib inline\n","train_samples = []\n","test_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'test')):\n","    test_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","train_samples = train_samples[start:end] # per testarne di meno di tutta la cartella\n","test_samples = test_samples[20:40]\n","\n","inference_with_plot(test_samples, draw_groundtruth=True, annotations_df=test_annotations, box_th=0.30)"]},{"cell_type":"markdown","metadata":{"id":"RWBHL14XwD2z"},"source":["## V2"]},{"cell_type":"markdown","metadata":{"id":"Jn3NmSWGwD2z"},"source":["### Configuration"]},{"cell_type":"code","source":["# efficientdet_d0_coco17_tpu-32\n","\n","# ----------------------------------- BEGIN MODEL SETTINGS --------------------------------------- #\n","%cd $pre_trained_models_path\n","# SET DOWNLOAD LINK AND MODEL TECH NAME + .tar.gz\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","# SET MODEL TECH NAME + .tar.gz\n","!tar -xf efficientdet_d0_coco17_tpu-32.tar.gz\n","%rm efficientdet_d0_coco17_tpu-32.tar.gz\n","\n","%cd .."],"metadata":{"id":"3n7bgEnYwD20"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKM1bEGJwD20"},"outputs":[],"source":["model_tech_name = 'efficientdet_d0_coco17_tpu-32'\n","model_name = 'efficientdet_d0'\n","version_name = 'v2'\n","\n","model_path = os.path.join(models_path, model_name)\n","version_path = os.path.join(model_path, version_name)\n","\n","train_log_path = os.path.join(version_path, 'train')\n","eval_log_path = os.path.join(version_path, 'eval')\n","log_path = version_path\n","\n","pre_trained_conf_path = os.path.join(pre_trained_models_path, model_tech_name, 'pipeline.config')\n","model_conf_path = os.path.join(models_path, model_name, version_name, 'pipeline.config')\n","checkpoint_path = os.path.join(pre_trained_models_path, model_tech_name, 'checkpoint/ckpt-0')\n","\n","model_name_version = model_name + '_' + version_name\n","exported_model_path = os.path.join(exported_models_path, model_name_version)\n","exported_model_conf_path = os.path.join(exported_models_path, model_name_version, 'pipeline.config')\n","\n","batch_size = 4\n","num_epoch = 15\n","num_steps = int(num_train_samples / batch_size) * num_epoch\n","num_steps += 100\n","print(num_steps)\n","# ------------------------------------- END MODEL SETTINGS --------------------------------------- #"]},{"cell_type":"code","source":["if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","if not os.path.exists(version_path):\n","    os.mkdir(version_path)\n","if not os.path.exists(version_path + \"/eval\"):\n","    os.mkdir(version_path + \"/eval\")\n","if not os.path.exists(version_path + \"/train\"):\n","    os.mkdir(version_path + \"/train\")\n","if not os.path.exists(version_path + \"/custom_ckpt\"):\n","    os.mkdir(version_path + \"/custom_ckpt\")\n","\n","shutil.copy(pre_trained_conf_path, model_conf_path)"],"metadata":{"id":"cwr33pO5wD20"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modifiche manuali al config file:\n","# momentum_optimizer sembra essere il migliore in termini di loss\n","'''\n","model {\n","  ssd {\n","    num_classes: 1\n","    image_resizer {\n","      fixed_shape_resizer {\n","          height: 512\n","          width: 512\n","      }\n","    }\n","\n","    feature_extractor {\n","      type: \"ssd_efficientnet-b0_bifpn_keras\"\n","      conv_hyperparams {\n","        regularizer {\n","          l2_regularizer {\n","            weight: 3.9999998989515007e-05\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            mean: 0.0\n","            stddev: 0.029999999329447746\n","          }\n","        }\n","        activation: SWISH\n","        batch_norm {\n","          decay: 0.9900000095367432\n","          scale: true\n","          epsilon: 0.0010000000474974513\n","        }\n","        force_use_bias: true\n","      }\n","      bifpn {\n","        min_level: 3\n","        max_level: 7\n","        num_iterations: 3\n","        num_filters: 64\n","      }\n","    }\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 1.0\n","        x_scale: 1.0\n","        height_scale: 1.0\n","        width_scale: 1.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        use_dropout: true\n","        dropout_keep_probability: 0.8\n","        conv_hyperparams {\n","          regularizer {\n","            l2_regularizer {\n","              weight: 3.9999998989515007e-05\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              mean: 0.0\n","              stddev: 0.009999999776482582\n","            }\n","          }\n","          activation: SWISH\n","          batch_norm {\n","            decay: 0.9900000095367432\n","            scale: true\n","            epsilon: 0.0010000000474974513\n","          }\n","          force_use_bias: true\n","        }\n","        depth: 64\n","        num_layers_before_predictor: 3\n","        kernel_size: 3\n","        class_prediction_bias_init: -4.599999904632568\n","        use_depthwise: true\n","      }\n","    }\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 3.0\n","        aspect_ratios: [0.5, 1.0, 1.5, 2.0]\n","        scales_per_octave: 3\n","      }\n","    }\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.2\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","    normalize_loss_by_num_matches: true\n","    loss {\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          gamma: 1.5\n","          alpha: 0.25\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 2.0\n","    }\n","    encode_background_as_zeros: true\n","    normalize_loc_loss_by_codesize: true\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    add_background_class: false\n","  }\n","}\n","\n","train_config {\n","  batch_size: 4\n","#  freeze_variables: [\"feature_extractor\"]\n","\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","    random_pixel_value_scale {\n","\n","    }\n","    random_adjust_brightness {\n","\n","    }\n","    random_adjust_contrast {\n","        \n","    }\n","  }\n","\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0003\n","          schedule {\n","            step: 15000\n","            learning_rate: 0.00003\n","          }\n","          schedule {\n","            step: 20000\n","            learning_rate: 0.00001\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n","  num_steps: 25200\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  fine_tune_checkpoint_type: \"detection\"\n","  use_bfloat16: false\n","  fine_tune_checkpoint_version: V2\n","}\n","train_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 1;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\"\n","  }\n","}\n","'''"],"metadata":{"id":"qVcdE8HqwD20"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","test_conf_path = version_path + \"/test.config\"\n","with open(model_conf_path, 'r') as f:\n","    config = f.read()\n","with open(test_conf_path, 'w') as f:\n","    config = re.sub('(input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")', 'input_path: \"{}\"'.format(test_record_path), config)\n","    f.write(config)"],"metadata":{"id":"1ZqHnmNwb8YN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HyXoTvizwD21"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZC2s9SAwD21"},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Jnp6uewwD21"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path/train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ma6cll39wD21"},"outputs":[],"source":["# TRAINING\n","#checkpoint_every_n = int(num_train_samples / batch_size)\n","checkpoint_every_n = 1000\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/model_main_tf2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --model_dir=$version_path \\\n","  --checkpoint_every_n=$checkpoint_every_n \\"]},{"cell_type":"code","source":["ckpt_path = version_path + \"/checkpoint\"\n","cust_ckpt_path = version_path + \"/custom_ckpt\"\n","ckpt_data = version_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx = version_path + \"/ckpt-26.index\"\n","ckpt_data2 = cust_ckpt_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx2 = cust_ckpt_path + \"/ckpt-26.index\"\n","!cp $ckpt_path $cust_ckpt_path/checkpoint\n","!mv $ckpt_data $ckpt_data2\n","!mv $ckpt_idx $ckpt_idx2\n","import re\n","with open(cust_ckpt_path + \"/checkpoint\", 'r') as f:\n","    content = f.read()\n","with open(cust_ckpt_path + \"/checkpoint\", 'w') as f:\n","    content = re.sub('(model_checkpoint_path: \"{}\")'.format(\"ckpt-26\"), 'model_checkpoint_path: \"{}\"'.format(\"ckpt-26\"), content)\n","    f.write(content)"],"metadata":{"id":"s5p1vro4EQz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggC9q0-swD21"},"outputs":[],"source":["# EXPORTER\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/exporter_main_v2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --trained_checkpoint_dir=$version_path/custom_ckpt \\\n","  --output_directory=$exported_model_path \\\n","  --input_type=image_tensor"]},{"cell_type":"markdown","metadata":{"id":"dJRi11ZywD21"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0zlXB2fwD21"},"outputs":[],"source":["import tensorflow as tf # import tensorflow\n","\n","# checking that GPU is found\n","if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")\n","\n","# other import\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","\n","%cd /content\n","\n","import sys # importyng sys in order to access scripts located in a different folder\n","\n","path2scripts = '/content/models/research' \n","sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n","\n","path2annotations = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","train_annotations = pd.read_csv(os.path.join(path2annotations, 'train.csv'))\n","test_annotations = pd.read_csv(os.path.join(path2annotations, 'test.csv'))\n","validation_annotations = pd.read_csv(os.path.join(path2annotations, 'validation.csv'))\n","\n","# importing all scripts that will be needed to export your model and use it for inference\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n","\n","# specify which device you want to work on.\n","# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # specify your computational device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1dOHBqHwD21"},"outputs":[],"source":["path2config = exported_model_conf_path\n","path2model = exported_model_path + '/'\n","\n","configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n","model_config = configs['model'] # recreating model config\n","detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(path2model, 'checkpoint/ckpt-0')).expect_partial()\n","\n","path2label_map = label_map_path\n","category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLITpvOfwD22"},"outputs":[],"source":["%matplotlib inline\n","train_samples = []\n","test_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'test')):\n","    test_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","train_samples = train_samples[start:end] # per testarne di meno di tutta la cartella\n","test_samples = test_samples[20:40]\n","\n","inference_with_plot(test_samples, draw_groundtruth=True, annotations_df=test_annotations, box_th=0.30)"]},{"cell_type":"markdown","metadata":{"id":"GgP-6t535FK0"},"source":["## V3"]},{"cell_type":"markdown","metadata":{"id":"BLaboQaJ5FK1"},"source":["### Configuration"]},{"cell_type":"code","source":["# efficientdet_d0_coco17_tpu-32\n","\n","# ----------------------------------- BEGIN MODEL SETTINGS --------------------------------------- #\n","%cd $pre_trained_models_path\n","# SET DOWNLOAD LINK AND MODEL TECH NAME + .tar.gz\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","# SET MODEL TECH NAME + .tar.gz\n","!tar -xf efficientdet_d0_coco17_tpu-32.tar.gz\n","%rm efficientdet_d0_coco17_tpu-32.tar.gz\n","\n","%cd .."],"metadata":{"id":"Z11BB-ci5FK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VNrSEfkA5FK1"},"outputs":[],"source":["model_tech_name = 'efficientdet_d0_coco17_tpu-32'\n","model_name = 'efficientdet_d0'\n","version_name = 'v3'\n","\n","model_path = os.path.join(models_path, model_name)\n","version_path = os.path.join(model_path, version_name)\n","\n","train_log_path = os.path.join(version_path, 'train')\n","eval_log_path = os.path.join(version_path, 'eval')\n","log_path = version_path\n","\n","pre_trained_conf_path = os.path.join(pre_trained_models_path, model_tech_name, 'pipeline.config')\n","model_conf_path = os.path.join(models_path, model_name, version_name, 'pipeline.config')\n","checkpoint_path = os.path.join(pre_trained_models_path, model_tech_name, 'checkpoint/ckpt-0')\n","\n","model_name_version = model_name + '_' + version_name\n","exported_model_path = os.path.join(exported_models_path, model_name_version)\n","exported_model_conf_path = os.path.join(exported_models_path, model_name_version, 'pipeline.config')\n","\n","batch_size = 4\n","num_epoch = 15\n","num_steps = int(num_train_samples / batch_size) * num_epoch\n","num_steps += 100\n","print(num_steps)\n","# ------------------------------------- END MODEL SETTINGS --------------------------------------- #"]},{"cell_type":"code","source":["if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","if not os.path.exists(version_path):\n","    os.mkdir(version_path)\n","if not os.path.exists(version_path + \"/eval\"):\n","    os.mkdir(version_path + \"/eval\")\n","if not os.path.exists(version_path + \"/train\"):\n","    os.mkdir(version_path + \"/train\")\n","if not os.path.exists(version_path + \"/custom_ckpt\"):\n","    os.mkdir(version_path + \"/custom_ckpt\")\n","\n","shutil.copy(pre_trained_conf_path, model_conf_path)"],"metadata":{"id":"IAV5Bkst5FK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modifiche manuali al config file:\n","# momentum_optimizer sembra essere il migliore in termini di loss\n","'''\n","model {\n","  ssd {\n","    num_classes: 1\n","    image_resizer {\n","      fixed_shape_resizer {\n","          height: 512\n","          width: 512\n","      }\n","    }\n","\n","    feature_extractor {\n","      type: \"ssd_efficientnet-b0_bifpn_keras\"\n","      conv_hyperparams {\n","        regularizer {\n","          l2_regularizer {\n","            weight: 3.9999998989515007e-05\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            mean: 0.0\n","            stddev: 0.029999999329447746\n","          }\n","        }\n","        activation: SWISH\n","        batch_norm {\n","          decay: 0.9900000095367432\n","          scale: true\n","          epsilon: 0.0010000000474974513\n","        }\n","        force_use_bias: true\n","      }\n","      bifpn {\n","        min_level: 3\n","        max_level: 7\n","        num_iterations: 3\n","        num_filters: 64\n","      }\n","    }\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 1.0\n","        x_scale: 1.0\n","        height_scale: 1.0\n","        width_scale: 1.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        use_dropout: true\n","        dropout_keep_probability: 0.8\n","        conv_hyperparams {\n","          regularizer {\n","            l2_regularizer {\n","              weight: 3.9999998989515007e-05\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              mean: 0.0\n","              stddev: 0.009999999776482582\n","            }\n","          }\n","          activation: SWISH\n","          batch_norm {\n","            decay: 0.9900000095367432\n","            scale: true\n","            epsilon: 0.0010000000474974513\n","          }\n","          force_use_bias: true\n","        }\n","        depth: 64\n","        num_layers_before_predictor: 3\n","        kernel_size: 3\n","        class_prediction_bias_init: -4.599999904632568\n","        use_depthwise: true\n","      }\n","    }\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 2.0\n","        aspect_ratios: [0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.25, 2.50, 2.75, 3.0]\n","        scales_per_octave: 3\n","      }\n","    }\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.2\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","    normalize_loss_by_num_matches: true\n","    loss {\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          gamma: 1.5\n","          alpha: 0.25\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 2.0\n","    }\n","    encode_background_as_zeros: true\n","    normalize_loc_loss_by_codesize: true\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    add_background_class: false\n","  }\n","}\n","\n","train_config {\n","  batch_size: 4\n","#  freeze_variables: [\"feature_extractor\"]\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","        probability: 0.5\n","    }\n","    random_pixel_value_scale {\n","        probability: 0.5\n","        minval: 0.9\n","        maxval: 1.1\n","    }\n","    random_adjust_brightness {\n","        probability: 0.5\n","        max_delta: 0.2\n","    }\n","    random_adjust_contrast {\n","        probability: 0.5\n","        min_delta: 0.8\n","        max_delta: 1.2\n","    }\n","  }\n","\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0003\n","          schedule {\n","            step: 15000\n","            learning_rate: 0.00003\n","          }\n","          schedule {\n","            step: 20000\n","            learning_rate: 0.00001\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n","  num_steps: 25200\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  fine_tune_checkpoint_type: \"detection\"\n","  use_bfloat16: false\n","  fine_tune_checkpoint_version: V2\n","}\n","train_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 1;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\"\n","  }\n","}\n","'''"],"metadata":{"id":"7Y4HMkED5FK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","test_conf_path = version_path + \"/test.config\"\n","with open(model_conf_path, 'r') as f:\n","    config = f.read()\n","with open(test_conf_path, 'w') as f:\n","    config = re.sub('(input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")', 'input_path: \"{}\"'.format(test_record_path), config)\n","    f.write(config)"],"metadata":{"id":"tIGhvKAg5FK2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9cMeSA4a5FK2"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wztvv8MH5FK2"},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_aGYSpGo5FK2"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path/train"]},{"cell_type":"code","source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path"],"metadata":{"id":"O7RUWxlFQ7Lq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgOsOWxL5FK2"},"outputs":[],"source":["# TRAINING\n","#checkpoint_every_n = int(num_train_samples / batch_size)\n","checkpoint_every_n = 1000\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/model_main_tf2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --model_dir=$version_path \\\n","  --checkpoint_every_n=$checkpoint_every_n \\"]},{"cell_type":"code","source":["ckpt_path = version_path + \"/checkpoint\"\n","cust_ckpt_path = version_path + \"/custom_ckpt\"\n","ckpt_data = version_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx = version_path + \"/ckpt-26.index\"\n","ckpt_data2 = cust_ckpt_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx2 = cust_ckpt_path + \"/ckpt-26.index\"\n","!cp $ckpt_path $cust_ckpt_path/checkpoint\n","!cp $ckpt_data $ckpt_data2\n","!cp $ckpt_idx $ckpt_idx2\n","import re\n","with open(cust_ckpt_path + \"/checkpoint\", 'r') as f:\n","    content = f.read()\n","with open(cust_ckpt_path + \"/checkpoint\", 'w') as f:\n","    content = re.sub('(model_checkpoint_path: \"{}\")'.format(\"ckpt-26\"), 'model_checkpoint_path: \"{}\"'.format(\"ckpt-26\"), content)\n","    f.write(content)"],"metadata":{"id":"WWmXuAvt5FK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_C9H90Ni5FK3"},"outputs":[],"source":["# EXPORTER\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/exporter_main_v2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --trained_checkpoint_dir=$version_path/custom_ckpt \\\n","  --output_directory=$exported_model_path \\\n","  --input_type=image_tensor"]},{"cell_type":"markdown","metadata":{"id":"sX64W7_e5FK3"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cu7Ftv4G5FK3"},"outputs":[],"source":["import tensorflow as tf # import tensorflow\n","\n","# checking that GPU is found\n","if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")\n","\n","# other import\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","import time\n","\n","%cd /content\n","\n","import sys # importyng sys in order to access scripts located in a different folder\n","\n","path2scripts = '/content/models/research' \n","sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n","\n","path2annotations = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","train_annotations = pd.read_csv(os.path.join(path2annotations, 'train.csv'))\n","test_annotations = pd.read_csv(os.path.join(path2annotations, 'test.csv'))\n","validation_annotations = pd.read_csv(os.path.join(path2annotations, 'validation.csv'))\n","\n","# importing all scripts that will be needed to export your model and use it for inference\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n","\n","# specify which device you want to work on.\n","# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # specify your computational device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4P1tHz75FK3"},"outputs":[],"source":["path2config = exported_model_conf_path\n","path2model = exported_model_path + '/'\n","\n","configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n","model_config = configs['model'] # recreating model config\n","detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(path2model, 'checkpoint/ckpt-0')).expect_partial()\n","\n","path2label_map = label_map_path\n","category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aj2P6TUn5FK3"},"outputs":[],"source":["%matplotlib inline\n","train_samples = []\n","test_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'test')):\n","    test_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","train_samples = train_samples[start:end] # per testarne di meno di tutta la cartella\n","test_samples = test_samples[20:40]\n","\n","inference_with_plot(test_samples, draw_groundtruth=True, annotations_df=test_annotations, box_th=0.30)"]},{"cell_type":"markdown","metadata":{"id":"1uE6gWFYLWYJ"},"source":["## V4"]},{"cell_type":"markdown","metadata":{"id":"jCmutg3zLWYK"},"source":["### Configuration"]},{"cell_type":"code","source":["# efficientdet_d0_coco17_tpu-32\n","\n","# ----------------------------------- BEGIN MODEL SETTINGS --------------------------------------- #\n","%cd $pre_trained_models_path\n","# SET DOWNLOAD LINK AND MODEL TECH NAME + .tar.gz\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n","# SET MODEL TECH NAME + .tar.gz\n","!tar -xf efficientdet_d0_coco17_tpu-32.tar.gz\n","%rm efficientdet_d0_coco17_tpu-32.tar.gz\n","\n","%cd .."],"metadata":{"id":"Dsm-oavGLWYK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nI4pxSHyLWYK"},"outputs":[],"source":["model_tech_name = 'efficientdet_d0_coco17_tpu-32'\n","model_name = 'efficientdet_d0'\n","version_name = 'v4'\n","\n","model_path = os.path.join(models_path, model_name)\n","version_path = os.path.join(model_path, version_name)\n","\n","train_log_path = os.path.join(version_path, 'train')\n","eval_log_path = os.path.join(version_path, 'eval')\n","log_path = version_path\n","\n","pre_trained_conf_path = os.path.join(pre_trained_models_path, model_tech_name, 'pipeline.config')\n","model_conf_path = os.path.join(models_path, model_name, version_name, 'pipeline.config')\n","checkpoint_path = os.path.join(pre_trained_models_path, model_tech_name, 'checkpoint/ckpt-0')\n","\n","model_name_version = model_name + '_' + version_name\n","exported_model_path = os.path.join(exported_models_path, model_name_version)\n","exported_model_conf_path = os.path.join(exported_models_path, model_name_version, 'pipeline.config')\n","\n","batch_size = 4\n","num_epoch = 15\n","num_steps = int(num_train_samples / batch_size) * num_epoch\n","num_steps += 100\n","print(num_steps)\n","# ------------------------------------- END MODEL SETTINGS --------------------------------------- #"]},{"cell_type":"code","source":["if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","if not os.path.exists(version_path):\n","    os.mkdir(version_path)\n","if not os.path.exists(version_path + \"/eval\"):\n","    os.mkdir(version_path + \"/eval\")\n","if not os.path.exists(version_path + \"/train\"):\n","    os.mkdir(version_path + \"/train\")\n","if not os.path.exists(version_path + \"/custom_ckpt\"):\n","    os.mkdir(version_path + \"/custom_ckpt\")\n","\n","shutil.copy(pre_trained_conf_path, model_conf_path)"],"metadata":{"id":"GZJomtpCLWYL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modifiche manuali al config file:\n","# momentum_optimizer sembra essere il migliore in termini di loss\n","'''\n","model {\n","  ssd {\n","    num_classes: 1\n","    image_resizer {\n","      fixed_shape_resizer {\n","          height: 512\n","          width: 512\n","      }\n","    }\n","\n","    feature_extractor {\n","      type: \"ssd_efficientnet-b0_bifpn_keras\"\n","      conv_hyperparams {\n","        regularizer {\n","          l2_regularizer {\n","            weight: 3.9999998989515007e-05\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            mean: 0.0\n","            stddev: 0.029999999329447746\n","          }\n","        }\n","        activation: SWISH\n","        batch_norm {\n","          decay: 0.9900000095367432\n","          scale: true\n","          epsilon: 0.0010000000474974513\n","        }\n","        force_use_bias: true\n","      }\n","      bifpn {\n","        min_level: 3\n","        max_level: 7\n","        num_iterations: 3\n","        num_filters: 64\n","      }\n","    }\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 1.0\n","        x_scale: 1.0\n","        height_scale: 1.0\n","        width_scale: 1.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        use_dropout: true\n","        dropout_keep_probability: 0.8\n","        conv_hyperparams {\n","          regularizer {\n","            l2_regularizer {\n","              weight: 3.9999998989515007e-05\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              mean: 0.0\n","              stddev: 0.009999999776482582\n","            }\n","          }\n","          activation: SWISH\n","          batch_norm {\n","            decay: 0.9900000095367432\n","            scale: true\n","            epsilon: 0.0010000000474974513\n","          }\n","          force_use_bias: true\n","        }\n","        depth: 64\n","        num_layers_before_predictor: 3\n","        kernel_size: 3\n","        class_prediction_bias_init: -4.599999904632568\n","        use_depthwise: true\n","      }\n","    }\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 2.0\n","        aspect_ratios: [0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.25, 2.50, 2.75, 3.0]\n","        scales_per_octave: 3\n","      }\n","    }\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.2\n","        iou_threshold: 0.1\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","    normalize_loss_by_num_matches: true\n","    loss {\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          gamma: 1.5\n","          alpha: 0.25\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 2.0\n","    }\n","    encode_background_as_zeros: true\n","    normalize_loc_loss_by_codesize: true\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    add_background_class: false\n","  }\n","}\n","\n","train_config {\n","#  freeze_variables: [\"feature_extractor\"]\n","  batch_size: 4\n","\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","        probability: 0.3\n","    }\n","    random_pixel_value_scale {\n","        minval: 0.9\n","        maxval: 1.2 \n","    }\n","    random_adjust_brightness {\n","        max_delta: 0.2\n","    }\n","    random_adjust_contrast {\n","        min_delta: 0.8\n","        max_delta: 1.2\n","    }\n","  }\n","\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 0.003\n","          total_steps: 25200\n","          warmup_learning_rate: 0.001\n","          warmup_steps: 1000\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n","  num_steps: 25200\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  fine_tune_checkpoint_type: \"detection\"\n","  use_bfloat16: false\n","  fine_tune_checkpoint_version: V2\n","}\n","train_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 1;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\"\n","  }\n","}\n","'''"],"metadata":{"id":"_SOuoaw3LWYL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","test_conf_path = version_path + \"/test.config\"\n","with open(model_conf_path, 'r') as f:\n","    config = f.read()\n","with open(test_conf_path, 'w') as f:\n","    config = re.sub('(input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")', 'input_path: \"{}\"'.format(test_record_path), config)\n","    f.write(config)"],"metadata":{"id":"_Y97fdQZLWYL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"it82twv3LWYM"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8iTAlgTXLWYM"},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"okFIbNVCLWYM"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path/train"]},{"cell_type":"code","source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path"],"metadata":{"id":"uS16clOlMuNe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZmzwEeJPLWYM"},"outputs":[],"source":["# TRAINING\n","#checkpoint_every_n = int(num_train_samples / batch_size)\n","checkpoint_every_n = 1000\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/model_main_tf2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --model_dir=$version_path \\\n","  --checkpoint_every_n=$checkpoint_every_n \\"]},{"cell_type":"code","source":["ckpt_path = version_path + \"/checkpoint\"\n","cust_ckpt_path = version_path + \"/custom_ckpt\"\n","ckpt_data = version_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx = version_path + \"/ckpt-26.index\"\n","ckpt_data2 = cust_ckpt_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx2 = cust_ckpt_path + \"/ckpt-26.index\"\n","!cp $ckpt_path $cust_ckpt_path/checkpoint\n","!cp $ckpt_data $ckpt_data2\n","!cp $ckpt_idx $ckpt_idx2\n","import re\n","with open(cust_ckpt_path + \"/checkpoint\", 'r') as f:\n","    content = f.read()\n","with open(cust_ckpt_path + \"/checkpoint\", 'w') as f:\n","    content = re.sub('(model_checkpoint_path: \"{}\")'.format(\"ckpt-26\"), 'model_checkpoint_path: \"{}\"'.format(\"ckpt-26\"), content)\n","    f.write(content)"],"metadata":{"id":"qtAmhUm9LWYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GlKlGo3LWYM"},"outputs":[],"source":["# EXPORTER\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/exporter_main_v2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --trained_checkpoint_dir=$version_path/custom_ckpt \\\n","  --output_directory=$exported_model_path \\\n","  --input_type=image_tensor"]},{"cell_type":"markdown","metadata":{"id":"kz1pSkN6LWYM"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GqWvFIA6LWYN"},"outputs":[],"source":["import tensorflow as tf # import tensorflow\n","\n","# checking that GPU is found\n","if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")\n","\n","# other import\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","\n","%cd /content\n","\n","import sys # importyng sys in order to access scripts located in a different folder\n","\n","path2scripts = '/content/models/research' \n","sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n","\n","path2annotations = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","train_annotations = pd.read_csv(os.path.join(path2annotations, 'train.csv'))\n","test_annotations = pd.read_csv(os.path.join(path2annotations, 'test.csv'))\n","validation_annotations = pd.read_csv(os.path.join(path2annotations, 'validation.csv'))\n","\n","# importing all scripts that will be needed to export your model and use it for inference\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n","\n","# specify which device you want to work on.\n","# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # specify your computational device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gpiz0wIVLWYN"},"outputs":[],"source":["path2config = exported_model_conf_path\n","path2model = exported_model_path + '/'\n","\n","configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n","model_config = configs['model'] # recreating model config\n","detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(path2model, 'checkpoint/ckpt-0')).expect_partial()\n","\n","path2label_map = label_map_path\n","category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F1aY11bpLWYN"},"outputs":[],"source":["%matplotlib inline\n","train_samples = []\n","test_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'test')):\n","    test_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","train_samples = train_samples[start:end] # per testarne di meno di tutta la cartella\n","test_samples = test_samples[20:40]\n","\n","inference_with_plot(test_samples, draw_groundtruth=True, annotations_df=test_annotations, box_th=0.30)"]},{"cell_type":"markdown","metadata":{"id":"7-xi6KIdpg4L"},"source":["# Faster R-CNN ResNet50 V1 640x640"]},{"cell_type":"markdown","metadata":{"id":"RooAQuc0FDCi"},"source":["## V1"]},{"cell_type":"markdown","metadata":{"id":"nlZYdACHFDCn"},"source":["### Configuration"]},{"cell_type":"code","source":["# faster_rcnn_resnet50_v1_640x640_coco17_tpu-8\n","\n","# ----------------------------------- BEGIN MODEL SETTINGS --------------------------------------- #\n","%cd $pre_trained_models_path\n","# SET DOWNLOAD LINK AND MODEL TECH NAME + .tar.gz\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","# SET MODEL TECH NAME + .tar.gz\n","!tar -xf faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","%rm faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","\n","%cd .."],"metadata":{"id":"Odn96YA1FDCn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wOE8vR99FDCo"},"outputs":[],"source":["model_tech_name = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n","model_name = 'faster_rcnn_resnet50'\n","version_name = 'v1'\n","\n","model_path = os.path.join(models_path, model_name)\n","version_path = os.path.join(model_path, version_name)\n","\n","train_log_path = os.path.join(version_path, 'train')\n","eval_log_path = os.path.join(version_path, 'eval')\n","log_path = version_path\n","\n","pre_trained_conf_path = os.path.join(pre_trained_models_path, model_tech_name, 'pipeline.config')\n","model_conf_path = os.path.join(models_path, model_name, version_name, 'pipeline.config')\n","checkpoint_path = os.path.join(pre_trained_models_path, model_tech_name, 'checkpoint/ckpt-0')\n","\n","model_name_version = model_name + '_' + version_name\n","exported_model_path = os.path.join(exported_models_path, model_name_version)\n","exported_model_conf_path = os.path.join(exported_models_path, model_name_version, 'pipeline.config')\n","\n","batch_size = 2\n","num_epoch = 15\n","num_steps = int(num_train_samples / batch_size) * num_epoch \n","num_steps += 100\n","print(num_steps)\n","# ------------------------------------- END MODEL SETTINGS --------------------------------------- #"]},{"cell_type":"code","source":["if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","if not os.path.exists(version_path):\n","    os.mkdir(version_path)\n","if not os.path.exists(version_path + \"/eval\"):\n","    os.mkdir(version_path + \"/eval\")\n","if not os.path.exists(version_path + \"/train\"):\n","    os.mkdir(version_path + \"/train\")\n","if not os.path.exists(version_path + \"/custom_ckpt\"):\n","    os.mkdir(version_path + \"/custom_ckpt\")\n","\n","shutil.copy(pre_trained_conf_path, model_conf_path)"],"metadata":{"id":"BurqcqjIFDCo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modifiche manuali al config file:\n","'''\n","# Faster R-CNN with Resnet-50 (v1)\n","# Trained on COCO, initialized from Imagenet classification checkpoint\n","\n","# Achieves -- mAP on COCO14 minival dataset.\n","\n","# This config is TPU compatible.\n","\n","model {\n","  faster_rcnn {\n","    num_classes: 1\n","    image_resizer {\n","      fixed_shape_resizer {\n","          height: 640\n","          width: 640\n","      }\n","    }\n","\n","    feature_extractor {\n","      type: 'faster_rcnn_resnet50_keras'\n","      batch_norm_trainable: true\n","    }\n","    first_stage_anchor_generator {\n","      grid_anchor_generator {\n","        scales: [0.25, 0.5, 1.0, 2.0, 3.0]\n","        aspect_ratios: [0.5, 1.0, 1.5, 2.0, 2.50, 3.0]\n","        height_stride: 16\n","        width_stride: 16\n","      }\n","    }\n","    first_stage_box_predictor_conv_hyperparams {\n","      op: CONV\n","      regularizer {\n","        l2_regularizer {\n","          weight: 0.0\n","        }\n","      }\n","      initializer {\n","        truncated_normal_initializer {\n","          stddev: 0.01\n","        }\n","      }\n","    }\n","    first_stage_nms_score_threshold: 0.0\n","    first_stage_nms_iou_threshold: 0.7\n","    first_stage_max_proposals: 300\n","    first_stage_localization_loss_weight: 2.0\n","    first_stage_objectness_loss_weight: 1.0\n","    initial_crop_size: 14\n","    maxpool_kernel_size: 2\n","    maxpool_stride: 2\n","    second_stage_box_predictor {\n","      mask_rcnn_box_predictor {\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        fc_hyperparams {\n","          op: FC\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.0\n","            }\n","          }\n","          initializer {\n","            variance_scaling_initializer {\n","              factor: 1.0\n","              uniform: true\n","              mode: FAN_AVG\n","            }\n","          }\n","        }\n","        share_box_across_classes: true\n","      }\n","    }\n","    second_stage_post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.2\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SOFTMAX\n","    }\n","    second_stage_localization_loss_weight: 1.5\n","    second_stage_classification_loss_weight: 1.0\n","    use_static_shapes: true\n","    use_matmul_crop_and_resize: true\n","    clip_anchors_to_image: true\n","    use_static_balanced_label_sampler: true\n","    use_matmul_gather_in_matcher: true\n","  }\n","}\n","\n","train_config {\n","  batch_size: 2\n","  num_steps: 25200\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0003\n","          schedule {\n","            step: 13000\n","            learning_rate: 0.00003\n","          }\n","          schedule {\n","            step: 20000\n","            learning_rate: 0.000003\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","        probability: 0.5\n","    }\n","    random_pixel_value_scale {\n","        minval: 0.9\n","        maxval: 1.2\n","    }\n","    random_adjust_brightness {\n","        max_delta: 0.2\n","    }\n","    random_adjust_contrast {\n","        min_delta: 0.8\n","        max_delta: 1.2\n","    }\n","  }\n","  \n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_type: \"detection\"\n","\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  use_bfloat16: false  # works only on TPUs\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 1\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\"\n","  }\n","}\n","'''"],"metadata":{"id":"2NncoAh_ILar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","test_conf_path = version_path + \"/test.config\"\n","with open(model_conf_path, 'r') as f:\n","    config = f.read()\n","with open(test_conf_path, 'w') as f:\n","    config = re.sub('(input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")', 'input_path: \"{}\"'.format(test_record_path), config)\n","    f.write(config)"],"metadata":{"id":"ZIO_gSgBkCgi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NLYjKCQkFDCp"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ilOcIvxMFDCp"},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImEXkDJSFDCp"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path/train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVKyi-xoFDCq"},"outputs":[],"source":["# TRAINING\n","#checkpoint_every_n = int(num_train_samples / batch_size)\n","checkpoint_every_n = 1000\n","\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/model_main_tf2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --model_dir=$version_path \\\n","  --checkpoint_every_n=$checkpoint_every_n \\"]},{"cell_type":"code","source":["ckpt_path = version_path + \"/checkpoint\"\n","cust_ckpt_path = version_path + \"/custom_ckpt\"\n","ckpt_data = version_path + \"/ckpt-51.data-00000-of-00001\"\n","ckpt_idx = version_path + \"/ckpt-51.index\"\n","ckpt_data2 = cust_ckpt_path + \"/ckpt-51.data-00000-of-00001\"\n","ckpt_idx2 = cust_ckpt_path + \"/ckpt-51.index\"\n","!cp $ckpt_path $cust_ckpt_path/checkpoint\n","!mv $ckpt_data $ckpt_data2\n","!mv $ckpt_idx $ckpt_idx2\n","import re\n","with open(cust_ckpt_path + \"/checkpoint\", 'r') as f:\n","    content = f.read()\n","with open(cust_ckpt_path + \"/checkpoint\", 'w') as f:\n","    content = re.sub('(model_checkpoint_path: \"{}\")'.format(\"ckpt-51\"), 'model_checkpoint_path: \"{}\"'.format(\"ckpt-51\"), content)\n","    f.write(content)"],"metadata":{"id":"CrqRe6NZ7fRi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_AtAYhqzFDCq"},"outputs":[],"source":["# EXPORTER\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/exporter_main_v2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --trained_checkpoint_dir=$version_path/custom_ckpt \\\n","  --output_directory=$exported_model_path \\\n","  --input_type=image_tensor"]},{"cell_type":"markdown","metadata":{"id":"MpkHV3PRFDCr"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0z1T7jk9FDCs"},"outputs":[],"source":["import tensorflow as tf # import tensorflow\n","\n","# checking that GPU is found\n","if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")\n","\n","# other import\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","\n","%cd /content\n","\n","import sys # importyng sys in order to access scripts located in a different folder\n","\n","path2scripts = '/content/models/research' \n","sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n","\n","path2annotations = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","train_annotations = pd.read_csv(os.path.join(path2annotations, 'train.csv'))\n","test_annotations = pd.read_csv(os.path.join(path2annotations, 'test.csv'))\n","validation_annotations = pd.read_csv(os.path.join(path2annotations, 'validation.csv'))\n","\n","# importing all scripts that will be needed to export your model and use it for inference\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n","\n","# specify which device you want to work on.\n","# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # specify your computational device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ugesd-REFDCs"},"outputs":[],"source":["path2config = exported_model_conf_path\n","path2model = exported_model_path + '/'\n","\n","configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n","model_config = configs['model'] # recreating model config\n","detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(path2model, 'checkpoint/ckpt-0')).expect_partial()\n","\n","path2label_map = label_map_path\n","category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wv0wU77xFDCs"},"outputs":[],"source":["%matplotlib inline\n","train_samples = []\n","test_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'test')):\n","    test_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","train_samples = train_samples[start:end] # per testarne di meno di tutta la cartella\n","test_samples = test_samples[20:40]\n","\n","inference_with_plot(test_samples, draw_groundtruth=True, annotations_df=test_annotations, box_th=0.30)"]},{"cell_type":"markdown","metadata":{"id":"PNxGZr7v541M"},"source":["## V2"]},{"cell_type":"markdown","metadata":{"id":"X3WTwir_541S"},"source":["### Configuration"]},{"cell_type":"code","source":["# faster_rcnn_resnet50_v1_640x640_coco17_tpu-8\n","\n","# ----------------------------------- BEGIN MODEL SETTINGS --------------------------------------- #\n","%cd $pre_trained_models_path\n","# SET DOWNLOAD LINK AND MODEL TECH NAME + .tar.gz\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","# SET MODEL TECH NAME + .tar.gz\n","!tar -xf faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","%rm faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","\n","%cd .."],"metadata":{"id":"FAoWN3-J541S"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lo82j_h6541T"},"outputs":[],"source":["model_tech_name = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n","model_name = 'faster_rcnn_resnet50'\n","version_name = 'v2'\n","\n","model_path = os.path.join(models_path, model_name)\n","version_path = os.path.join(model_path, version_name)\n","\n","train_log_path = os.path.join(version_path, 'train')\n","eval_log_path = os.path.join(version_path, 'eval')\n","log_path = version_path\n","\n","pre_trained_conf_path = os.path.join(pre_trained_models_path, model_tech_name, 'pipeline.config')\n","model_conf_path = os.path.join(models_path, model_name, version_name, 'pipeline.config')\n","checkpoint_path = os.path.join(pre_trained_models_path, model_tech_name, 'checkpoint/ckpt-0')\n","\n","model_name_version = model_name + '_' + version_name\n","exported_model_path = os.path.join(exported_models_path, model_name_version)\n","exported_model_conf_path = os.path.join(exported_models_path, model_name_version, 'pipeline.config')\n","\n","batch_size = 2\n","num_epoch = 15\n","num_steps = int(num_train_samples / batch_size) * num_epoch \n","num_steps += 100\n","print(num_steps)\n","# ------------------------------------- END MODEL SETTINGS --------------------------------------- #"]},{"cell_type":"code","source":["if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","if not os.path.exists(version_path):\n","    os.mkdir(version_path)\n","if not os.path.exists(version_path + \"/eval\"):\n","    os.mkdir(version_path + \"/eval\")\n","if not os.path.exists(version_path + \"/train\"):\n","    os.mkdir(version_path + \"/train\")\n","if not os.path.exists(version_path + \"/custom_ckpt\"):\n","    os.mkdir(version_path + \"/custom_ckpt\")\n","\n","shutil.copy(pre_trained_conf_path, model_conf_path)"],"metadata":{"id":"KtZ-vRRN541T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modifiche manuali al config file:\n","'''\n","# Faster R-CNN with Resnet-50 (v1)\n","# Trained on COCO, initialized from Imagenet classification checkpoint\n","\n","# Achieves -- mAP on COCO14 minival dataset.\n","\n","# This config is TPU compatible.\n","\n","model {\n","  faster_rcnn {\n","    num_classes: 1\n","    image_resizer {\n","      fixed_shape_resizer {\n","          height: 640\n","          width: 640\n","      }\n","    }\n","\n","    feature_extractor {\n","      type: 'faster_rcnn_resnet50_keras'\n","      batch_norm_trainable: true\n","    }\n","    first_stage_anchor_generator {\n","      grid_anchor_generator {\n","        scales: [0.25, 0.5, 1.0, 2.0, 3.0]\n","        aspect_ratios: [0.5, 1.0, 1.5, 2.0]\n","        height_stride: 8\n","        width_stride: 8\n","      }\n","    }\n","    first_stage_box_predictor_conv_hyperparams {\n","      op: CONV\n","      regularizer {\n","        l2_regularizer {\n","          weight: 0.0\n","        }\n","      }\n","      initializer {\n","        truncated_normal_initializer {\n","          stddev: 0.01\n","        }\n","      }\n","    }\n","    first_stage_nms_score_threshold: 0.0\n","    first_stage_nms_iou_threshold: 0.7\n","    first_stage_max_proposals: 300\n","    first_stage_localization_loss_weight: 2.0\n","    first_stage_objectness_loss_weight: 1.0\n","    initial_crop_size: 14\n","    maxpool_kernel_size: 2\n","    maxpool_stride: 2\n","    second_stage_box_predictor {\n","      mask_rcnn_box_predictor {\n","        use_dropout: true\n","        dropout_keep_probability: 0.8\n","        fc_hyperparams {\n","          op: FC\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.0\n","            }\n","          }\n","          initializer {\n","            variance_scaling_initializer {\n","              factor: 1.0\n","              uniform: true\n","              mode: FAN_AVG\n","            }\n","          }\n","        }\n","        share_box_across_classes: true\n","      }\n","    }\n","    second_stage_post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.2\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SOFTMAX\n","    }\n","    second_stage_localization_loss_weight: 1.5\n","    second_stage_classification_loss_weight: 1.0\n","    use_static_shapes: true\n","    use_matmul_crop_and_resize: true\n","    clip_anchors_to_image: true\n","    use_static_balanced_label_sampler: true\n","    use_matmul_gather_in_matcher: true\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 2\n","#  freeze_variables: [\"feature_extractor\"]\n","  num_steps: 50400\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0003\n","          schedule {\n","            step: 25000\n","            learning_rate: 0.00003\n","          }\n","          schedule {\n","            step: 40000\n","            learning_rate: 0.000003\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_type: \"detection\"\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","    random_pixel_value_scale {\n","\n","    }\n","    random_adjust_brightness {\n","\n","    }\n","    random_adjust_contrast {\n","        \n","    }\n","  }\n","\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  use_bfloat16: false  # works only on TPUs\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 1\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\"\n","  }\n","}\n","'''"],"metadata":{"id":"nGP85g_b541U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","test_conf_path = version_path + \"/test.config\"\n","with open(model_conf_path, 'r') as f:\n","    config = f.read()\n","with open(test_conf_path, 'w') as f:\n","    config = re.sub('(input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")', 'input_path: \"{}\"'.format(test_record_path), config)\n","    f.write(config)"],"metadata":{"id":"FPuqV6ui541U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VhVPnP6W541U"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPL9JhdX541V"},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4f05DaM541V"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path/train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"14Jq1qSf541V"},"outputs":[],"source":["# TRAINING\n","#checkpoint_every_n = int(num_train_samples / batch_size)\n","checkpoint_every_n = 1000\n","\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/model_main_tf2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --model_dir=$version_path \\\n","  --checkpoint_every_n=$checkpoint_every_n \\"]},{"cell_type":"code","source":["ckpt_path = version_path + \"/checkpoint\"\n","cust_ckpt_path = version_path + \"/custom_ckpt\"\n","ckpt_data = version_path + \"/ckpt-51.data-00000-of-00001\"\n","ckpt_idx = version_path + \"/ckpt-51.index\"\n","ckpt_data2 = cust_ckpt_path + \"/ckpt-51.data-00000-of-00001\"\n","ckpt_idx2 = cust_ckpt_path + \"/ckpt-51.index\"\n","!cp $ckpt_path $cust_ckpt_path/checkpoint\n","!mv $ckpt_data $ckpt_data2\n","!mv $ckpt_idx $ckpt_idx2\n","import re\n","with open(cust_ckpt_path + \"/checkpoint\", 'r') as f:\n","    content = f.read()\n","with open(cust_ckpt_path + \"/checkpoint\", 'w') as f:\n","    content = re.sub('(model_checkpoint_path: \"{}\")'.format(\"ckpt-51\"), 'model_checkpoint_path: \"{}\"'.format(\"ckpt-46\"), content)\n","    f.write(content)"],"metadata":{"id":"8ts1nTr4541V"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qqo4K4hJ541W"},"outputs":[],"source":["# EXPORTER\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/exporter_main_v2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --trained_checkpoint_dir=$version_path/custom_ckpt \\\n","  --output_directory=$exported_model_path \\\n","  --input_type=image_tensor"]},{"cell_type":"markdown","metadata":{"id":"d_QzF4kt541W"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pP-qEn5541W"},"outputs":[],"source":["import tensorflow as tf # import tensorflow\n","\n","# checking that GPU is found\n","if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")\n","\n","# other import\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","\n","%cd /content\n","\n","import sys # importyng sys in order to access scripts located in a different folder\n","\n","path2scripts = '/content/models/research' \n","sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n","\n","path2annotations = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","train_annotations = pd.read_csv(os.path.join(path2annotations, 'train.csv'))\n","test_annotations = pd.read_csv(os.path.join(path2annotations, 'test.csv'))\n","validation_annotations = pd.read_csv(os.path.join(path2annotations, 'validation.csv'))\n","\n","# importing all scripts that will be needed to export your model and use it for inference\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n","\n","# specify which device you want to work on.\n","# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" # specify your computational device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMspsqmQ541W"},"outputs":[],"source":["path2config = exported_model_conf_path\n","path2model = exported_model_path + '/'\n","\n","configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n","model_config = configs['model'] # recreating model config\n","detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(path2model, 'checkpoint/ckpt-0')).expect_partial()\n","\n","path2label_map = label_map_path\n","category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bLa_e-NI541X"},"outputs":[],"source":["%matplotlib inline\n","train_samples = []\n","test_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'test')):\n","    test_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","train_samples = train_samples[start:end] # per testarne di meno di tutta la cartella\n","test_samples = test_samples[20:40]\n","\n","inference_with_plot(test_samples, draw_groundtruth=True, annotations_df=test_annotations, box_th=0.30)"]},{"cell_type":"markdown","metadata":{"id":"eIO9_fdCFPgH"},"source":["## V3"]},{"cell_type":"markdown","metadata":{"id":"qG2EWFJhFPgI"},"source":["### Configuration"]},{"cell_type":"code","source":["# faster_rcnn_resnet50_v1_640x640_coco17_tpu-8\n","\n","# ----------------------------------- BEGIN MODEL SETTINGS --------------------------------------- #\n","%cd $pre_trained_models_path\n","# SET DOWNLOAD LINK AND MODEL TECH NAME + .tar.gz\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","# SET MODEL TECH NAME + .tar.gz\n","!tar -xf faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","%rm faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","\n","%cd .."],"metadata":{"id":"snFyWNH0FPgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Sk94noSFPgI"},"outputs":[],"source":["model_tech_name = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n","model_name = 'faster_rcnn_resnet50'\n","version_name = 'v3'\n","\n","model_path = os.path.join(models_path, model_name)\n","version_path = os.path.join(model_path, version_name)\n","\n","train_log_path = os.path.join(version_path, 'train')\n","eval_log_path = os.path.join(version_path, 'eval')\n","log_path = version_path\n","\n","pre_trained_conf_path = os.path.join(pre_trained_models_path, model_tech_name, 'pipeline.config')\n","model_conf_path = os.path.join(models_path, model_name, version_name, 'pipeline.config')\n","checkpoint_path = os.path.join(pre_trained_models_path, model_tech_name, 'checkpoint/ckpt-0')\n","\n","model_name_version = model_name + '_' + version_name\n","exported_model_path = os.path.join(exported_models_path, model_name_version)\n","exported_model_conf_path = os.path.join(exported_models_path, model_name_version, 'pipeline.config')\n","\n","batch_size = 2\n","num_epoch = 7.5\n","num_steps = int(num_train_samples / batch_size) * num_epoch \n","num_steps += 100\n","print(num_steps)\n","# ------------------------------------- END MODEL SETTINGS --------------------------------------- #"]},{"cell_type":"code","source":["if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","if not os.path.exists(version_path):\n","    os.mkdir(version_path)\n","if not os.path.exists(version_path + \"/eval\"):\n","    os.mkdir(version_path + \"/eval\")\n","if not os.path.exists(version_path + \"/train\"):\n","    os.mkdir(version_path + \"/train\")\n","if not os.path.exists(version_path + \"/custom_ckpt\"):\n","    os.mkdir(version_path + \"/custom_ckpt\")\n","\n","shutil.copy(pre_trained_conf_path, model_conf_path)"],"metadata":{"id":"W0GGwSENFPgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modifiche manuali al config file:\n","'''\n","# Faster R-CNN with Resnet-50 (v1)\n","# Trained on COCO, initialized from Imagenet classification checkpoint\n","\n","# Achieves -- mAP on COCO14 minival dataset.\n","\n","# This config is TPU compatible.\n","\n","model {\n","  faster_rcnn {\n","    num_classes: 1\n","    image_resizer {\n","      fixed_shape_resizer {\n","          height: 640\n","          width: 640\n","      }\n","    }\n","\n","    feature_extractor {\n","      type: 'faster_rcnn_resnet50_keras'\n","      batch_norm_trainable: true\n","    }\n","\n","    first_stage_anchor_generator {\n","      grid_anchor_generator {\n","        scales: [0.5, 1.0, 2.0]\n","        aspect_ratios: [0.5, 1.0, 2.0]\n","        height_stride: 16\n","        width_stride: 16\n","      }\n","    }\n","    first_stage_box_predictor_conv_hyperparams {\n","      op: CONV\n","      regularizer {\n","        l2_regularizer {\n","          weight: 3.9999998989515007e-05\n","        }\n","      }\n","      initializer {\n","        truncated_normal_initializer {\n","          stddev: 0.01\n","        }\n","      }\n","    }\n","    first_stage_nms_score_threshold: 0.2\n","    first_stage_nms_iou_threshold: 0.7\n","    first_stage_max_proposals: 300\n","    first_stage_localization_loss_weight: 2.0\n","    first_stage_objectness_loss_weight: 1.0\n","    initial_crop_size: 14\n","    maxpool_kernel_size: 2\n","    maxpool_stride: 2\n","    second_stage_box_predictor {\n","      mask_rcnn_box_predictor {\n","        use_dropout: false\n","        dropout_keep_probability: 1.0\n","        fc_hyperparams {\n","          op: FC\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.0\n","            }\n","          }\n","          initializer {\n","            variance_scaling_initializer {\n","              factor: 1.0\n","              uniform: true\n","              mode: FAN_AVG\n","            }\n","          }\n","        }\n","        share_box_across_classes: true\n","      }\n","    }\n","    second_stage_post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.2\n","        iou_threshold: 0.5\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SOFTMAX\n","    }\n","    second_stage_localization_loss_weight: 2.0\n","    second_stage_classification_loss_weight: 1.0\n","    use_static_shapes: true\n","    use_matmul_crop_and_resize: true\n","    clip_anchors_to_image: true\n","    use_static_balanced_label_sampler: true\n","    use_matmul_gather_in_matcher: true\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 2\n","  num_steps: 25200\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 0.003\n","          total_steps: 25200\n","          warmup_learning_rate: 0.001\n","          warmup_steps: 1000\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_type: \"detection\"\n","\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_adjust_brightness {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_adjust_contrast {\n","    }\n","  }\n","\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  use_bfloat16: false  # works only on TPUs\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/data/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 1\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\"\n","  }\n","}\n","'''"],"metadata":{"id":"iphATGJvFPgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","test_conf_path = version_path + \"/test.config\"\n","with open(model_conf_path, 'r') as f:\n","    config = f.read()\n","with open(test_conf_path, 'w') as f:\n","    config = re.sub('(input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")', 'input_path: \"{}\"'.format(test_record_path), config)\n","    f.write(config)"],"metadata":{"id":"Wj5_Ku2_FPgI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QP6ujVRvFPgJ"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebSRrgN2FPgJ"},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDMYV94BFPgJ"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path/train"]},{"cell_type":"code","source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path"],"metadata":{"id":"j6RyeICw93j-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record /content/data/train.record"],"metadata":{"id":"Js4IzMSN0nY3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt /content/data/label_map.pbtxt"],"metadata":{"id":"L6ZeARZl1A3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2KDTirLFPgJ"},"outputs":[],"source":["# TRAINING\n","#checkpoint_every_n = int(num_train_samples / batch_size)\n","checkpoint_every_n = 1000\n","\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/model_main_tf2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --model_dir=$version_path \\\n","  --checkpoint_every_n=$checkpoint_every_n \\"]},{"cell_type":"code","source":["ckpt_path = version_path + \"/checkpoint\"\n","cust_ckpt_path = version_path + \"/custom_ckpt\"\n","ckpt_data = version_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx = version_path + \"/ckpt-26.index\"\n","ckpt_data2 = cust_ckpt_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx2 = cust_ckpt_path + \"/ckpt-26.index\"\n","!cp $ckpt_path $cust_ckpt_path/checkpoint\n","!cp $ckpt_data $ckpt_data2\n","!cp $ckpt_idx $ckpt_idx2\n","import re\n","with open(cust_ckpt_path + \"/checkpoint\", 'r') as f:\n","    content = f.read()\n","with open(cust_ckpt_path + \"/checkpoint\", 'w') as f:\n","    content = re.sub('(model_checkpoint_path: \"{}\")'.format(\"ckpt-26\"), 'model_checkpoint_path: \"{}\"'.format(\"ckpt-26\"), content)\n","    f.write(content)"],"metadata":{"id":"X6slcvbxFPgJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7UGDE7bmFPgJ"},"outputs":[],"source":["# EXPORTER\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/exporter_main_v2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --trained_checkpoint_dir=$version_path/custom_ckpt \\\n","  --output_directory=$exported_model_path \\\n","  --input_type=image_tensor"]},{"cell_type":"markdown","metadata":{"id":"TZSBkD6qFPgJ"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q3KVIbDeFPgJ"},"outputs":[],"source":["import tensorflow as tf # import tensorflow\n","\n","# checking that GPU is found\n","if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")\n","\n","# other import\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","import time\n","\n","%cd /content\n","\n","import sys # importyng sys in order to access scripts located in a different folder\n","\n","path2scripts = '/content/models/research' \n","sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n","\n","path2annotations = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","train_annotations = pd.read_csv(os.path.join(path2annotations, 'train.csv'))\n","test_annotations = pd.read_csv(os.path.join(path2annotations, 'test.csv'))\n","validation_annotations = pd.read_csv(os.path.join(path2annotations, 'validation.csv'))\n","\n","# importing all scripts that will be needed to export your model and use it for inference\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n","\n","# specify which device you want to work on.\n","# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" # specify your computational device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUlxj-zlFPgJ"},"outputs":[],"source":["path2config = exported_model_conf_path\n","path2model = exported_model_path + '/'\n","\n","configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n","model_config = configs['model'] # recreating model config\n","detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(path2model, 'checkpoint/ckpt-0')).expect_partial()\n","\n","path2label_map = label_map_path\n","category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1ndVA5qFPgK"},"outputs":[],"source":["%matplotlib inline\n","train_samples = []\n","test_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'test')):\n","    test_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","train_samples = train_samples[start:end] # per testarne di meno di tutta la cartella\n","test_samples = test_samples[20:40]\n","\n","inference_with_plot(test_samples, draw_groundtruth=True, annotations_df=test_annotations, box_th=0.30)"]},{"cell_type":"code","source":["%matplotlib inline\n","eval_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'validation')):\n","    eval_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","eval_samples = eval_samples[0:50]\n","\n","inference_with_plot(eval_samples, draw_groundtruth=True, annotations_df=validation_annotations, box_th=0.30)"],"metadata":{"id":"HG_j7LESA1GV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NF0BwuCoMQbq"},"source":["## V4"]},{"cell_type":"markdown","metadata":{"id":"jx3DN2BAMQbq"},"source":["### Configuration"]},{"cell_type":"code","source":["# faster_rcnn_resnet50_v1_640x640_coco17_tpu-8\n","\n","# ----------------------------------- BEGIN MODEL SETTINGS --------------------------------------- #\n","%cd $pre_trained_models_path\n","# SET DOWNLOAD LINK AND MODEL TECH NAME + .tar.gz\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","# SET MODEL TECH NAME + .tar.gz\n","!tar -xf faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","%rm faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n","\n","%cd .."],"metadata":{"id":"XJ51SKY1MQbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OOtuwVVxMQbr"},"outputs":[],"source":["model_tech_name = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n","model_name = 'faster_rcnn_resnet50'\n","version_name = 'v4'\n","\n","model_path = os.path.join(models_path, model_name)\n","version_path = os.path.join(model_path, version_name)\n","\n","train_log_path = os.path.join(version_path, 'train')\n","eval_log_path = os.path.join(version_path, 'eval')\n","log_path = version_path\n","\n","pre_trained_conf_path = os.path.join(pre_trained_models_path, model_tech_name, 'pipeline.config')\n","model_conf_path = os.path.join(models_path, model_name, version_name, 'pipeline.config')\n","checkpoint_path = os.path.join(pre_trained_models_path, model_tech_name, 'checkpoint/ckpt-0')\n","\n","model_name_version = model_name + '_' + version_name\n","exported_model_path = os.path.join(exported_models_path, model_name_version)\n","exported_model_conf_path = os.path.join(exported_models_path, model_name_version, 'pipeline.config')\n","\n","batch_size = 2\n","num_epoch = 7.5\n","num_steps = int(num_train_samples / batch_size) * num_epoch \n","num_steps += 100\n","print(num_steps)\n","# ------------------------------------- END MODEL SETTINGS --------------------------------------- #"]},{"cell_type":"code","source":["if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","if not os.path.exists(version_path):\n","    os.mkdir(version_path)\n","if not os.path.exists(version_path + \"/eval\"):\n","    os.mkdir(version_path + \"/eval\")\n","if not os.path.exists(version_path + \"/train\"):\n","    os.mkdir(version_path + \"/train\")\n","if not os.path.exists(version_path + \"/custom_ckpt\"):\n","    os.mkdir(version_path + \"/custom_ckpt\")\n","\n","shutil.copy(pre_trained_conf_path, model_conf_path)"],"metadata":{"id":"trXnTqvVMQbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modifiche manuali al config file:\n","'''\n","# Faster R-CNN with Resnet-50 (v1)\n","# Trained on COCO, initialized from Imagenet classification checkpoint\n","\n","# Achieves -- mAP on COCO14 minival dataset.\n","\n","# This config is TPU compatible.\n","\n","model {\n","  faster_rcnn {\n","    num_classes: 1\n","    image_resizer {\n","      keep_aspect_ratio_resizer {\n","        min_dimension: 640\n","        max_dimension: 640\n","        pad_to_max_dimension: true\n","      }\n","    }\n","    feature_extractor {\n","      type: 'faster_rcnn_resnet50_keras'\n","      batch_norm_trainable: true\n","    }\n","    first_stage_anchor_generator {\n","      grid_anchor_generator {\n","        scales: [0.25, 0.5, 1.0, 2.0]\n","        aspect_ratios: [0.5, 1.0, 2.0]\n","        height_stride: 16\n","        width_stride: 16\n","      }\n","    }\n","    first_stage_box_predictor_conv_hyperparams {\n","      op: CONV\n","      regularizer {\n","        l2_regularizer {\n","          weight: 0.0\n","        }\n","      }\n","      initializer {\n","        truncated_normal_initializer {\n","          stddev: 0.01\n","        }\n","      }\n","    }\n","    first_stage_nms_score_threshold: 0.2\n","    first_stage_nms_iou_threshold: 0.7\n","    first_stage_max_proposals: 300\n","    first_stage_localization_loss_weight: 2.0\n","    first_stage_objectness_loss_weight: 1.0\n","    initial_crop_size: 14\n","    maxpool_kernel_size: 2\n","    maxpool_stride: 2\n","    second_stage_box_predictor {\n","      mask_rcnn_box_predictor {\n","        use_dropout: true\n","        dropout_keep_probability: 0.8\n","        fc_hyperparams {\n","          op: FC\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.0\n","            }\n","          }\n","          initializer {\n","            variance_scaling_initializer {\n","              factor: 1.0\n","              uniform: true\n","              mode: FAN_AVG\n","            }\n","          }\n","        }\n","        share_box_across_classes: true\n","      }\n","    }\n","    second_stage_post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.2\n","        iou_threshold: 0.1\n","        max_detections_per_class: 100\n","        max_total_detections: 300\n","      }\n","      score_converter: SOFTMAX\n","    }\n","    second_stage_localization_loss_weight: 2.0\n","    second_stage_classification_loss_weight: 1.0\n","    use_static_shapes: true\n","    use_matmul_crop_and_resize: true\n","    clip_anchors_to_image: true\n","    use_static_balanced_label_sampler: true\n","    use_matmul_gather_in_matcher: true\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 2\n","  num_steps: 25100\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.01\n","          schedule {\n","            step: 5000\n","            learning_rate: 0.001\n","          }\n","          schedule {\n","            step: 10000\n","            learning_rate: 0.0001\n","          }\n","          schedule {\n","            step: 15000\n","            learning_rate: 0.00001\n","          }\n","          schedule {\n","            step: 20000\n","            learning_rate: 0.000001\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","\n","\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/pre_trained_models/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_type: \"detection\"\n","\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  use_bfloat16: true  # works only on TPUs\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/data/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/data/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 1\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\"\n","  }\n","}\n","\n","'''"],"metadata":{"id":"ier1VWwwMQbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","test_conf_path = version_path + \"/test.config\"\n","with open(model_conf_path, 'r') as f:\n","    config = f.read()\n","with open(test_conf_path, 'w') as f:\n","    config = re.sub('(input_path: \"/content/drive/MyDrive/CVproject_Stenosis/workspace/data/validation.record\")', 'input_path: \"{}\"'.format(test_record_path), config)\n","    f.write(config)"],"metadata":{"id":"uypRJB6IMQbs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z169pKG3MQbs"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xufj9jYVMQbs"},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzkYDXMnMQbs"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path/train"]},{"cell_type":"code","source":["%reload_ext tensorboard\n","%tensorboard --logdir $log_path"],"metadata":{"id":"8y4enDfoJ5rI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/CVproject_Stenosis/workspace/data/train.record /content/data/train.record"],"metadata":{"id":"YsyMNpseMQbt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/CVproject_Stenosis/workspace/data/label_map.pbtxt /content/data/label_map.pbtxt"],"metadata":{"id":"DpoAP967MQbt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5dT0581UMQbt"},"outputs":[],"source":["# TRAINING\n","#checkpoint_every_n = int(num_train_samples / batch_size)\n","checkpoint_every_n = 1000\n","\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/model_main_tf2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --model_dir=$version_path \\\n","  --checkpoint_every_n=$checkpoint_every_n \\"]},{"cell_type":"code","source":["ckpt_path = version_path + \"/checkpoint\"\n","cust_ckpt_path = version_path + \"/custom_ckpt\"\n","ckpt_data = version_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx = version_path + \"/ckpt-26.index\"\n","ckpt_data2 = cust_ckpt_path + \"/ckpt-26.data-00000-of-00001\"\n","ckpt_idx2 = cust_ckpt_path + \"/ckpt-26.index\"\n","!cp $ckpt_path $cust_ckpt_path/checkpoint\n","!cp $ckpt_data $ckpt_data2\n","!cp $ckpt_idx $ckpt_idx2\n","import re\n","with open(cust_ckpt_path + \"/checkpoint\", 'r') as f:\n","    content = f.read()\n","with open(cust_ckpt_path + \"/checkpoint\", 'w') as f:\n","    content = re.sub('(model_checkpoint_path: \"{}\")'.format(\"ckpt-26\"), 'model_checkpoint_path: \"{}\"'.format(\"ckpt-26\"), content)\n","    f.write(content)"],"metadata":{"id":"8bMakKgKMQbt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9CNNOm43MQbu"},"outputs":[],"source":["# EXPORTER\n","!python /content/drive/MyDrive/CVproject_Stenosis/workspace/exporter_main_v2.py \\\n","  --pipeline_config_path=$model_conf_path \\\n","  --trained_checkpoint_dir=$version_path/custom_ckpt \\\n","  --output_directory=$exported_model_path \\\n","  --input_type=image_tensor"]},{"cell_type":"markdown","metadata":{"id":"mR3YNPH3MQbu"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCcBf1BRMQbu"},"outputs":[],"source":["import tensorflow as tf # import tensorflow\n","\n","# checking that GPU is found\n","if tf.test.gpu_device_name():\n","    print('GPU found')\n","else:\n","    print(\"No GPU found\")\n","\n","# other import\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","\n","%cd /content\n","\n","import sys # importyng sys in order to access scripts located in a different folder\n","\n","path2scripts = '/content/models/research' \n","sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n","\n","path2annotations = '/content/drive/MyDrive/CVproject_Stenosis/Dataset/CSV'\n","train_annotations = pd.read_csv(os.path.join(path2annotations, 'train.csv'))\n","test_annotations = pd.read_csv(os.path.join(path2annotations, 'test.csv'))\n","validation_annotations = pd.read_csv(os.path.join(path2annotations, 'validation.csv'))\n","\n","# importing all scripts that will be needed to export your model and use it for inference\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n","\n","# specify which device you want to work on.\n","# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" # specify your computational device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Q0cXbh6MQbu"},"outputs":[],"source":["path2config = exported_model_conf_path\n","path2model = exported_model_path + '/'\n","\n","configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n","model_config = configs['model'] # recreating model config\n","detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(path2model, 'checkpoint/ckpt-0')).expect_partial()\n","\n","path2label_map = label_map_path\n","category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vz7UX5JmMQbu"},"outputs":[],"source":["%matplotlib inline\n","train_samples = []\n","test_samples = []\n","\n","for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'test')):\n","    test_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","#for (path, dirnames, filenames) in os.walk(os.path.join(images_path, 'train')):\n","#    train_samples.extend(os.path.join(path, name) for name in filenames)\n","\n","import random\n","start = random.randint(0,200)\n","end = start + 20\n","train_samples = train_samples[start:end] # per testarne di meno di tutta la cartella\n","test_samples = test_samples[20:40]\n","\n","inference_with_plot(test_samples, draw_groundtruth=True, annotations_df=test_annotations, box_th=0.30)"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}